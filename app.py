import streamlit as st
import pandas as pd
import re
import json
import os
import sys
from pathlib import Path

# å¯¼å…¥è‡ªåŠ¨æ›´æ–°æ¨¡å—
try:
    from auto_updater import AutoUpdater, VersionManager
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œåˆ›å»ºç©ºçš„ç±»ä»¥é¿å…é”™è¯¯
    class AutoUpdater:
        def __init__(self, *args, **kwargs):
            pass
        def check_for_updates(self, *args, **kwargs):
            return {'has_update': False}
    
    class VersionManager:
        def __init__(self):
            self.current_version = '1.0.0'

# --- é¡µé¢åŸºç¡€è®¾ç½® ---
st.set_page_config(page_title="MICE TICKETING APP", layout="wide")

# åˆå§‹åŒ–ç‰ˆæœ¬ç®¡ç†å™¨
version_manager = VersionManager()
current_version = version_manager.current_version

st.title(f"âœˆï¸ MICE TICKETING APP V{current_version}")
st.markdown("ä¸Šä¼ å®¢æˆ·ä¿¡æ¯è¡¨ï¼Œé€‰æ‹©ä¸“å®¶å³å¯è‡ªåŠ¨å¡«å……ä¿¡æ¯ï¼Œå‘Šåˆ«æ‰‹åŠ¨è¾“å…¥ï¼")

# è‡ªåŠ¨æ›´æ–°æ£€æŸ¥ï¼ˆåœ¨ä¾§è¾¹æ æ˜¾ç¤ºï¼‰
with st.sidebar:
    st.markdown("### ğŸ“± åº”ç”¨ä¿¡æ¯")
    st.info(f"å½“å‰ç‰ˆæœ¬ï¼šV{current_version}")
    
    # æ£€æŸ¥æ›´æ–°æŒ‰é’®
    if st.button("ğŸ”„ æ£€æŸ¥æ›´æ–°", help="æ£€æŸ¥æ˜¯å¦æœ‰æ–°ç‰ˆæœ¬å¯ç”¨"):
        with st.spinner("æ­£åœ¨æ£€æŸ¥æ›´æ–°..."):
            try:
                # è¿™é‡Œéœ€è¦ç”¨æˆ·é…ç½®è‡ªå·±çš„GitHubä»“åº“ä¿¡æ¯
                # æ ¼å¼ï¼šAutoUpdater("ç”¨æˆ·å", "ä»“åº“å")
                # è¯·å°†ä¸‹é¢çš„ç”¨æˆ·åå’Œä»“åº“åæ›¿æ¢ä¸ºæ‚¨çš„å®é™…GitHubä¿¡æ¯
                updater = AutoUpdater("your-github-username", "mice-ticketing-app")
                update_info = updater.check_for_updates(current_version)
                
                if update_info['has_update']:
                    st.success(f"ğŸ‰ å‘ç°æ–°ç‰ˆæœ¬ V{update_info['version']}")
                    
                    # æ˜¾ç¤ºæ›´æ–°è¯´æ˜
                    if update_info.get('release_notes'):
                        with st.expander("ğŸ“‹ æ›´æ–°è¯´æ˜"):
                            st.markdown(update_info['release_notes'])
                    
                    # æ›´æ–°æŒ‰é’®
                    if st.button("â¬‡ï¸ ç«‹å³æ›´æ–°", type="primary"):
                        with st.spinner("æ­£åœ¨ä¸‹è½½æ›´æ–°..."):
                            if updater.download_and_install(update_info['download_url']):
                                st.success("âœ… æ›´æ–°ä¸‹è½½å®Œæˆï¼Œåº”ç”¨å°†é‡å¯")
                                st.balloons()
                            else:
                                st.error("âŒ æ›´æ–°å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•æˆ–æ‰‹åŠ¨ä¸‹è½½")
                else:
                    st.success("âœ… å½“å‰å·²æ˜¯æœ€æ–°ç‰ˆæœ¬")
            except Exception as e:
                st.warning(f"âš ï¸ æ£€æŸ¥æ›´æ–°å¤±è´¥ï¼š{str(e)}")
                st.info("ğŸ’¡ è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•")
    
    # åº”ç”¨ä¿¡æ¯
    with st.expander("â„¹ï¸ å…³äºåº”ç”¨"):
        st.markdown("""
        **æ™ºèƒ½ä¼šåŠ¡æœºç¥¨åŠ©æ‰‹**
        
        ğŸ¯ **ä¸»è¦åŠŸèƒ½ï¼š**
        - Excelæ–‡ä»¶ä¸Šä¼ ä¸è§£æ
        - è¯¢ä»·ä¿¡æ¯è‡ªåŠ¨ç”Ÿæˆ
        - ç¥¨åŠ¡å›å¤æ™ºèƒ½å¤„ç†
        - ä»·æ ¼ä¿¡æ¯è‡ªåŠ¨æ¸…æ´—
        - æ‰‹æœºå·ç æ ¼å¼éªŒè¯
        - è‡ªåŠ¨æ›´æ–°åŠŸèƒ½
        
        ğŸ”’ **æ•°æ®å®‰å…¨ï¼š**
        - æ‰€æœ‰æ•°æ®ä»…åœ¨æœ¬åœ°å¤„ç†
        - ä¸ä¸Šä¼ ä»»ä½•ä¸ªäººä¿¡æ¯
        - ç¬¦åˆæ•°æ®ä¿æŠ¤è¦æ±‚
        
        ğŸ“ **æŠ€æœ¯æ”¯æŒï¼š**
        - å¦‚æœ‰é—®é¢˜è¯·è”ç³»å¼€å‘å›¢é˜Ÿ
        - å»ºè®®å’Œåé¦ˆéšæ—¶æ¬¢è¿
        """)

st.markdown("---")

# --- æ ¸å¿ƒä¿®æ”¹ç‚¹ 1 ---
# æ›´æ–°å¿…éœ€åˆ—çš„å®šä¹‰ï¼Œä½¿å…¶ä¸æ‚¨Excelæ–‡ä»¶ä¸­çš„åˆ—åï¼ˆåŒ…å«ç©ºæ ¼ï¼‰å®Œå…¨åŒ¹é…
REQUIRED_COLUMNS = ['å§“å*', 'èº«ä»½è¯ (å‡ºæœºç¥¨å¿…é¡»å¡«å†™)', 'æ‰‹æœºå·ç  (å¿…å¡«)', 'é”€å”®æ‰‹æœº', 'å»ç¨‹è½¦æ¬¡/èˆªç­', 'è¿”ç¨‹è½¦æ¬¡/èˆªç­', 'å»ç¨‹å‡ºå‘æ—¥æœŸ', 'è¿”ç¨‹å‡ºå‘æ—¥æœŸ', 'å»ç¨‹å‡ºå‘æ—¶é—´', 'å»ç¨‹åˆ°è¾¾æ—¶é—´', 'è¿”ç¨‹å‡ºå‘æ—¶é—´', 'è¿”ç¨‹åˆ°è¾¾æ—¶é—´', 'å»ç¨‹å‡ºå‘ç«™', 'å»ç¨‹åˆ°è¾¾ç«™', 'è¿”ç¨‹å‡ºå‘ç«™', 'è¿”ç¨‹åˆ°è¾¾ç«™']

# æ™ºèƒ½æ¨¡ç³ŠåŒ¹é…çš„åˆ—åå˜ä½“é…ç½®
COLUMN_VARIANTS = {
    'å§“å*': [
        'å§“å', 'åå­—', 'ä¸“å®¶å§“å', 'å§“å*', 'ä¸“å®¶åå­—', 'äººå‘˜å§“å', 
        'å‚ä¼šäººå§“å', 'å‚ä¼šè€…å§“å', 'ä¼šè®®ä¸“å®¶å§“å', 'ä¸“å®¶', 'äººå‘˜',
        'name', 'Name', 'NAME', 'çœŸå®å§“å', 'å…¨å'
    ],
    'èº«ä»½è¯ (å‡ºæœºç¥¨å¿…é¡»å¡«å†™)': [
        'èº«ä»½è¯', 'èº«ä»½è¯å·', 'èº«ä»½è¯å·ç ', 'è¯ä»¶å·', 'è¯ä»¶å·ç ',
        'èº«ä»½è¯ (å‡ºæœºç¥¨å¿…é¡»å¡«å†™)', 'èº«ä»½è¯(å‡ºæœºç¥¨å¿…é¡»å¡«å†™)',
        'ID', 'id', 'Id', 'IDå·', 'IDå·ç ', 'èº«ä»½è¯ä»¶å·',
        'å±…æ°‘èº«ä»½è¯å·', 'èº«ä»½è¯ä»¶', 'è¯ä»¶', 'èº«ä»½è¯ä¿¡æ¯'
    ],
    'æ‰‹æœºå·ç  (å¿…å¡«)': [
        'æ‰‹æœº', 'æ‰‹æœºå·', 'æ‰‹æœºå·ç ', 'ç”µè¯', 'ç”µè¯å·ç ', 'è”ç³»ç”µè¯',
        'æ‰‹æœºå·ç  (å¿…å¡«)', 'æ‰‹æœºå·ç (å¿…å¡«)', 'ç§»åŠ¨ç”µè¯', 'è”ç³»æ–¹å¼',
        'phone', 'Phone', 'PHONE', 'mobile', 'Mobile', 'MOBILE',
        'æ‰‹æœºè”ç³»æ–¹å¼', 'ä¸ªäººç”µè¯', 'è”ç³»æ‰‹æœº'
    ],
    'é”€å”®æ‰‹æœº': [
        'é”€å”®æ‰‹æœº', 'é”€å”®ç”µè¯', 'é”€å”®æ‰‹æœºå·', 'é”€å”®æ‰‹æœºå·ç ', 'é”€å”®è”ç³»æ–¹å¼',
        'ç¥¨åŠ¡æ‰‹æœº', 'ç¥¨åŠ¡ç”µè¯', 'ç¥¨åŠ¡è”ç³»æ–¹å¼', 'å‡ºç¥¨æ‰‹æœº', 'å‡ºç¥¨ç”µè¯',
        'ç¬¬äºŒæ‰‹æœº', 'å¤‡ç”¨æ‰‹æœº', 'å¤‡ç”¨ç”µè¯', 'æ¥æ”¶æ‰‹æœº', 'æ¥æ”¶ç”µè¯',
        'çŸ­ä¿¡æ¥æ”¶æ‰‹æœº', 'çŸ­ä¿¡æ‰‹æœº', 'é€šçŸ¥æ‰‹æœº', 'é€šçŸ¥ç”µè¯'
    ],
    'å»ç¨‹è½¦æ¬¡/èˆªç­': [
        'å»ç¨‹è½¦æ¬¡', 'å»ç¨‹èˆªç­', 'å»ç¨‹è½¦æ¬¡/èˆªç­', 'å»ç¨‹èˆªç­å·', 'å»ç¨‹è½¦æ¬¡å·',
        'å‡ºå‘è½¦æ¬¡', 'å‡ºå‘èˆªç­', 'å‡ºå‘èˆªç­å·', 'å‡ºå‘è½¦æ¬¡å·', 'å»ç¨‹ç­æ¬¡',
        'å»ç¨‹äº¤é€š', 'å»ç¨‹ä¿¡æ¯', 'å‡ºè¡Œè½¦æ¬¡', 'å‡ºè¡Œèˆªç­', 'å¾€ç¨‹è½¦æ¬¡',
        'å¾€ç¨‹èˆªç­', 'ä¸Šè¡Œè½¦æ¬¡', 'ä¸Šè¡Œèˆªç­', 'å»ç¨‹', 'å‡ºå‘ç­æ¬¡'
    ],
    'è¿”ç¨‹è½¦æ¬¡/èˆªç­': [
        'è¿”ç¨‹è½¦æ¬¡', 'è¿”ç¨‹èˆªç­', 'è¿”ç¨‹è½¦æ¬¡/èˆªç­', 'è¿”ç¨‹èˆªç­å·', 'è¿”ç¨‹è½¦æ¬¡å·',
        'å›ç¨‹è½¦æ¬¡', 'å›ç¨‹èˆªç­', 'å›ç¨‹èˆªç­å·', 'å›ç¨‹è½¦æ¬¡å·', 'è¿”ç¨‹ç­æ¬¡',
        'è¿”ç¨‹äº¤é€š', 'è¿”ç¨‹ä¿¡æ¯', 'å›ç¨‹äº¤é€š', 'å›ç¨‹ä¿¡æ¯', 'ä¸‹è¡Œè½¦æ¬¡',
        'ä¸‹è¡Œèˆªç­', 'è¿”ç¨‹', 'å›ç¨‹ç­æ¬¡', 'å½’ç¨‹è½¦æ¬¡', 'å½’ç¨‹èˆªç­'
    ],
    'å»ç¨‹å‡ºå‘æ—¥æœŸ': [
        'å»ç¨‹å‡ºå‘æ—¥æœŸ', 'å»ç¨‹æ—¥æœŸ', 'å‡ºå‘æ—¥æœŸ', 'å»ç¨‹æ—¶é—´', 'å‡ºå‘æ—¶é—´',
        'å»ç¨‹å‡ºå‘æ—¶é—´', 'å‡ºè¡Œæ—¥æœŸ', 'å¾€ç¨‹æ—¥æœŸ', 'ä¸Šè¡Œæ—¥æœŸ', 'å»ç¨‹',
        'å‡ºå‘', 'å¯ç¨‹æ—¥æœŸ', 'å‡ºè¡Œæ—¶é—´', 'å»ç¨‹å‡ºå‘', 'å‡ºå‘æ—¥',
        'departure_date', 'outbound_date', 'å»ç¨‹æ—¥', 'å‡ºå‘æ—¥æœŸæ—¶é—´'
    ],
    'è¿”ç¨‹å‡ºå‘æ—¥æœŸ': [
        'è¿”ç¨‹å‡ºå‘æ—¥æœŸ', 'è¿”ç¨‹æ—¥æœŸ', 'å›ç¨‹æ—¥æœŸ', 'è¿”ç¨‹æ—¶é—´', 'å›ç¨‹æ—¶é—´',
        'è¿”ç¨‹å‡ºå‘æ—¶é—´', 'å›ç¨‹å‡ºå‘æ—¥æœŸ', 'ä¸‹è¡Œæ—¥æœŸ', 'å½’ç¨‹æ—¥æœŸ', 'è¿”ç¨‹',
        'å›ç¨‹', 'è¿”å›æ—¥æœŸ', 'å›ç¨‹å‡ºå‘', 'è¿”ç¨‹æ—¥', 'å›ç¨‹æ—¥',
        'return_date', 'inbound_date', 'è¿”ç¨‹å‡ºå‘', 'å›ç¨‹æ—¥æœŸæ—¶é—´'
    ],
    'å»ç¨‹å‡ºå‘ç«™': [
        'å»ç¨‹å‡ºå‘ç«™', 'å»ç¨‹å‡ºå‘åœ°', 'å‡ºå‘ç«™', 'å‡ºå‘åœ°', 'èµ·ç‚¹ç«™', 'èµ·ç‚¹',
        'å»ç¨‹èµ·ç‚¹', 'å‡ºå‘åŸå¸‚', 'å‡ºå‘æœºåœº', 'å‡ºå‘ç«è½¦ç«™', 'å§‹å‘ç«™',
        'å»ç¨‹å§‹å‘ç«™', 'ä¸Šè½¦ç«™', 'ç™»æœºåœ°', 'å‡ºå‘ç‚¹', 'èµ·å§‹ç«™',
        'departure_station', 'origin', 'å»ç¨‹å‡ºå‘', 'å‡ºå‘åœ°ç‚¹'
    ],
    'å»ç¨‹åˆ°è¾¾ç«™': [
        'å»ç¨‹åˆ°è¾¾ç«™', 'å»ç¨‹åˆ°è¾¾åœ°', 'åˆ°è¾¾ç«™', 'åˆ°è¾¾åœ°', 'ç»ˆç‚¹ç«™', 'ç»ˆç‚¹',
        'å»ç¨‹ç»ˆç‚¹', 'åˆ°è¾¾åŸå¸‚', 'åˆ°è¾¾æœºåœº', 'åˆ°è¾¾ç«è½¦ç«™', 'ç›®çš„ç«™',
        'å»ç¨‹ç›®çš„ç«™', 'ä¸‹è½¦ç«™', 'é™è½åœ°', 'åˆ°è¾¾ç‚¹', 'ç›®çš„åœ°',
        'arrival_station', 'destination', 'å»ç¨‹åˆ°è¾¾', 'åˆ°è¾¾åœ°ç‚¹'
    ],
    'è¿”ç¨‹å‡ºå‘ç«™': [
        'è¿”ç¨‹å‡ºå‘ç«™', 'è¿”ç¨‹å‡ºå‘åœ°', 'å›ç¨‹å‡ºå‘ç«™', 'å›ç¨‹å‡ºå‘åœ°', 'è¿”ç¨‹èµ·ç‚¹',
        'å›ç¨‹èµ·ç‚¹', 'è¿”ç¨‹å§‹å‘ç«™', 'å›ç¨‹å§‹å‘åœ°', 'è¿”ç¨‹ä¸Šè½¦ç«™', 'å›ç¨‹ç™»æœºåœ°',
        'è¿”ç¨‹å‡ºå‘åŸå¸‚', 'è¿”ç¨‹å‡ºå‘æœºåœº', 'è¿”ç¨‹å‡ºå‘ç«è½¦ç«™', 'å½’ç¨‹å‡ºå‘ç«™',
        'return_departure_station', 'è¿”ç¨‹å‡ºå‘', 'å›ç¨‹å‡ºå‘ç‚¹'
    ],
    'è¿”ç¨‹åˆ°è¾¾ç«™': [
        'è¿”ç¨‹åˆ°è¾¾ç«™', 'è¿”ç¨‹åˆ°è¾¾åœ°', 'å›ç¨‹åˆ°è¾¾ç«™', 'å›ç¨‹åˆ°è¾¾åœ°', 'è¿”ç¨‹ç»ˆç‚¹',
        'å›ç¨‹ç»ˆç‚¹', 'è¿”ç¨‹ç›®çš„ç«™', 'å›ç¨‹ç›®çš„åœ°', 'è¿”ç¨‹ä¸‹è½¦ç«™', 'å›ç¨‹é™è½åœ°',
        'è¿”ç¨‹åˆ°è¾¾åŸå¸‚', 'è¿”ç¨‹åˆ°è¾¾æœºåœº', 'è¿”ç¨‹åˆ°è¾¾ç«è½¦ç«™', 'å½’ç¨‹åˆ°è¾¾ç«™',
        'return_arrival_station', 'è¿”ç¨‹åˆ°è¾¾', 'å›ç¨‹åˆ°è¾¾ç‚¹'
    ],
    'å»ç¨‹å‡ºå‘æ—¶é—´': [
        'å»ç¨‹å‡ºå‘æ—¶é—´', 'å»ç¨‹æ—¶é—´', 'å‡ºå‘æ—¶é—´', 'å»ç¨‹èµ·é£æ—¶é—´', 'å»ç¨‹å‘è½¦æ—¶é—´',
        'å‡ºå‘æ—¶åˆ»', 'å»ç¨‹å‡ºå‘æ—¶åˆ»', 'å¯ç¨‹æ—¶é—´', 'å‡ºè¡Œæ—¶é—´', 'å»ç¨‹å¼€å§‹æ—¶é—´',
        'å‡ºå‘ç‚¹æ—¶é—´', 'èµ·å§‹æ—¶é—´', 'å»ç¨‹æ—¶åˆ»', 'å‡ºå‘ç­æ¬¡æ—¶é—´', 'å»ç¨‹ç­æ¬¡æ—¶é—´',
        'departure_time', 'outbound_time', 'å»ç¨‹å‘è½¦', 'å‡ºå‘æ—¶åˆ†'
    ],
    'å»ç¨‹åˆ°è¾¾æ—¶é—´': [
        'å»ç¨‹åˆ°è¾¾æ—¶é—´', 'å»ç¨‹æŠµè¾¾æ—¶é—´', 'åˆ°è¾¾æ—¶é—´', 'å»ç¨‹è½åœ°æ—¶é—´', 'å»ç¨‹åˆ°ç«™æ—¶é—´',
        'åˆ°è¾¾æ—¶åˆ»', 'å»ç¨‹åˆ°è¾¾æ—¶åˆ»', 'æŠµè¾¾æ—¶é—´', 'å»ç¨‹ç»“æŸæ—¶é—´', 'ç›®çš„åœ°æ—¶é—´',
        'åˆ°è¾¾ç‚¹æ—¶é—´', 'ç»ˆç‚¹æ—¶é—´', 'å»ç¨‹åˆ°æ—¶', 'åˆ°è¾¾ç­æ¬¡æ—¶é—´', 'å»ç¨‹ç­æ¬¡åˆ°è¾¾',
        'arrival_time', 'outbound_arrival_time', 'å»ç¨‹åˆ°ç«™', 'åˆ°è¾¾æ—¶åˆ†'
    ],
    'è¿”ç¨‹å‡ºå‘æ—¶é—´': [
        'è¿”ç¨‹å‡ºå‘æ—¶é—´', 'è¿”ç¨‹æ—¶é—´', 'å›ç¨‹å‡ºå‘æ—¶é—´', 'è¿”ç¨‹èµ·é£æ—¶é—´', 'è¿”ç¨‹å‘è½¦æ—¶é—´',
        'å›ç¨‹æ—¶é—´', 'è¿”ç¨‹å‡ºå‘æ—¶åˆ»', 'å›ç¨‹å‡ºå‘æ—¶åˆ»', 'è¿”ç¨‹å¼€å§‹æ—¶é—´', 'å›ç¨‹èµ·å§‹æ—¶é—´',
        'è¿”ç¨‹å‘è½¦', 'å›ç¨‹å‘è½¦æ—¶é—´', 'è¿”ç¨‹æ—¶åˆ»', 'å›ç¨‹ç­æ¬¡æ—¶é—´', 'å½’ç¨‹å‡ºå‘æ—¶é—´',
        'return_departure_time', 'return_time', 'è¿”ç¨‹å‘è½¦', 'å›ç¨‹æ—¶åˆ†'
    ],
    'è¿”ç¨‹åˆ°è¾¾æ—¶é—´': [
        'è¿”ç¨‹åˆ°è¾¾æ—¶é—´', 'è¿”ç¨‹æŠµè¾¾æ—¶é—´', 'å›ç¨‹åˆ°è¾¾æ—¶é—´', 'è¿”ç¨‹è½åœ°æ—¶é—´', 'è¿”ç¨‹åˆ°ç«™æ—¶é—´',
        'å›ç¨‹æŠµè¾¾æ—¶é—´', 'è¿”ç¨‹åˆ°è¾¾æ—¶åˆ»', 'å›ç¨‹åˆ°è¾¾æ—¶åˆ»', 'è¿”ç¨‹ç»“æŸæ—¶é—´', 'å›ç¨‹ç»ˆç‚¹æ—¶é—´',
        'è¿”ç¨‹åˆ°ç«™', 'å›ç¨‹åˆ°ç«™æ—¶é—´', 'è¿”ç¨‹åˆ°æ—¶', 'å›ç¨‹ç­æ¬¡åˆ°è¾¾', 'å½’ç¨‹åˆ°è¾¾æ—¶é—´',
        'return_arrival_time', 'inbound_arrival_time', 'è¿”ç¨‹åˆ°ç«™', 'å›ç¨‹æ—¶åˆ†'
    ]
}

# é¢„è®¾çš„å¸¸è§åˆ—ä½ç½®é…ç½®
DEFAULT_COLUMN_MAPPING = {
    'å§“å*': 0,  # Aåˆ—
    'èº«ä»½è¯ (å‡ºæœºç¥¨å¿…é¡»å¡«å†™)': 1,  # Båˆ—
    'æ‰‹æœºå·ç  (å¿…å¡«)': 2,   # Cåˆ—
    'é”€å”®æ‰‹æœº': 3,   # Dåˆ—
    'å»ç¨‹è½¦æ¬¡/èˆªç­': 4,   # Eåˆ—
    'è¿”ç¨‹è½¦æ¬¡/èˆªç­': 5,   # Fåˆ—
    'å»ç¨‹å‡ºå‘æ—¥æœŸ': 6,   # Gåˆ—
    'è¿”ç¨‹å‡ºå‘æ—¥æœŸ': 7,   # Håˆ—
    'å»ç¨‹å‡ºå‘æ—¶é—´': 8,   # Iåˆ—
    'å»ç¨‹åˆ°è¾¾æ—¶é—´': 9,   # Jåˆ—
    'è¿”ç¨‹å‡ºå‘æ—¶é—´': 10,  # Kåˆ—
    'è¿”ç¨‹åˆ°è¾¾æ—¶é—´': 11,  # Låˆ—
    'å»ç¨‹å‡ºå‘ç«™': 12,   # Måˆ—
    'å»ç¨‹åˆ°è¾¾ç«™': 13,   # Nåˆ—
    'è¿”ç¨‹å‡ºå‘ç«™': 14,   # Oåˆ—
    'è¿”ç¨‹åˆ°è¾¾ç«™': 15    # Påˆ—
}

# å¸¸è§Excelæ ¼å¼é¢„è®¾é…ç½®
PRESET_CONFIGURATIONS = {
    'æ ‡å‡†æ ¼å¼': {
        'description': 'å§“å-èº«ä»½è¯-æ‰‹æœºå·-é”€å”®æ‰‹æœº-å»ç¨‹è½¦æ¬¡-è¿”ç¨‹è½¦æ¬¡-å»ç¨‹æ—¥æœŸ-è¿”ç¨‹æ—¥æœŸ-å»ç¨‹å‡ºå‘æ—¶é—´-å»ç¨‹åˆ°è¾¾æ—¶é—´-è¿”ç¨‹å‡ºå‘æ—¶é—´-è¿”ç¨‹åˆ°è¾¾æ—¶é—´-å»ç¨‹å‡ºå‘ç«™-å»ç¨‹åˆ°è¾¾ç«™-è¿”ç¨‹å‡ºå‘ç«™-è¿”ç¨‹åˆ°è¾¾ç«™ (A-Påˆ—)',
        'mapping': {'å§“å*': 0, 'èº«ä»½è¯ (å‡ºæœºç¥¨å¿…é¡»å¡«å†™)': 1, 'æ‰‹æœºå·ç  (å¿…å¡«)': 2, 'é”€å”®æ‰‹æœº': 3, 'å»ç¨‹è½¦æ¬¡/èˆªç­': 4, 'è¿”ç¨‹è½¦æ¬¡/èˆªç­': 5, 'å»ç¨‹å‡ºå‘æ—¥æœŸ': 6, 'è¿”ç¨‹å‡ºå‘æ—¥æœŸ': 7, 'å»ç¨‹å‡ºå‘æ—¶é—´': 8, 'å»ç¨‹åˆ°è¾¾æ—¶é—´': 9, 'è¿”ç¨‹å‡ºå‘æ—¶é—´': 10, 'è¿”ç¨‹åˆ°è¾¾æ—¶é—´': 11, 'å»ç¨‹å‡ºå‘ç«™': 12, 'å»ç¨‹åˆ°è¾¾ç«™': 13, 'è¿”ç¨‹å‡ºå‘ç«™': 14, 'è¿”ç¨‹åˆ°è¾¾ç«™': 15}
    },
    'ä¼šè®®æ ¼å¼1': {
        'description': 'åºå·-å§“å-èº«ä»½è¯-æ‰‹æœºå·-é”€å”®æ‰‹æœº-å»ç¨‹è½¦æ¬¡-è¿”ç¨‹è½¦æ¬¡-å»ç¨‹æ—¥æœŸ-è¿”ç¨‹æ—¥æœŸ-å»ç¨‹å‡ºå‘æ—¶é—´-å»ç¨‹åˆ°è¾¾æ—¶é—´-è¿”ç¨‹å‡ºå‘æ—¶é—´-è¿”ç¨‹åˆ°è¾¾æ—¶é—´-å»ç¨‹å‡ºå‘ç«™-å»ç¨‹åˆ°è¾¾ç«™-è¿”ç¨‹å‡ºå‘ç«™-è¿”ç¨‹åˆ°è¾¾ç«™ (B-Qåˆ—)',
        'mapping': {'å§“å*': 1, 'èº«ä»½è¯ (å‡ºæœºç¥¨å¿…é¡»å¡«å†™)': 2, 'æ‰‹æœºå·ç  (å¿…å¡«)': 3, 'é”€å”®æ‰‹æœº': 4, 'å»ç¨‹è½¦æ¬¡/èˆªç­': 5, 'è¿”ç¨‹è½¦æ¬¡/èˆªç­': 6, 'å»ç¨‹å‡ºå‘æ—¥æœŸ': 7, 'è¿”ç¨‹å‡ºå‘æ—¥æœŸ': 8, 'å»ç¨‹å‡ºå‘æ—¶é—´': 9, 'å»ç¨‹åˆ°è¾¾æ—¶é—´': 10, 'è¿”ç¨‹å‡ºå‘æ—¶é—´': 11, 'è¿”ç¨‹åˆ°è¾¾æ—¶é—´': 12, 'å»ç¨‹å‡ºå‘ç«™': 13, 'å»ç¨‹åˆ°è¾¾ç«™': 14, 'è¿”ç¨‹å‡ºå‘ç«™': 15, 'è¿”ç¨‹åˆ°è¾¾ç«™': 16}
    },
    'ä¼šè®®æ ¼å¼2': {
        'description': 'å§“å-æ‰‹æœºå·-èº«ä»½è¯-é”€å”®æ‰‹æœº-å»ç¨‹è½¦æ¬¡-è¿”ç¨‹è½¦æ¬¡-å»ç¨‹æ—¥æœŸ-è¿”ç¨‹æ—¥æœŸ-å»ç¨‹å‡ºå‘æ—¶é—´-å»ç¨‹åˆ°è¾¾æ—¶é—´-è¿”ç¨‹å‡ºå‘æ—¶é—´-è¿”ç¨‹åˆ°è¾¾æ—¶é—´-å»ç¨‹å‡ºå‘ç«™-å»ç¨‹åˆ°è¾¾ç«™-è¿”ç¨‹å‡ºå‘ç«™-è¿”ç¨‹åˆ°è¾¾ç«™ (A-Påˆ—)',
        'mapping': {'å§“å*': 0, 'æ‰‹æœºå·ç  (å¿…å¡«)': 1, 'èº«ä»½è¯ (å‡ºæœºç¥¨å¿…é¡»å¡«å†™)': 2, 'é”€å”®æ‰‹æœº': 3, 'å»ç¨‹è½¦æ¬¡/èˆªç­': 4, 'è¿”ç¨‹è½¦æ¬¡/èˆªç­': 5, 'å»ç¨‹å‡ºå‘æ—¥æœŸ': 6, 'è¿”ç¨‹å‡ºå‘æ—¥æœŸ': 7, 'å»ç¨‹å‡ºå‘æ—¶é—´': 8, 'å»ç¨‹åˆ°è¾¾æ—¶é—´': 9, 'è¿”ç¨‹å‡ºå‘æ—¶é—´': 10, 'è¿”ç¨‹åˆ°è¾¾æ—¶é—´': 11, 'å»ç¨‹å‡ºå‘ç«™': 12, 'å»ç¨‹åˆ°è¾¾ç«™': 13, 'è¿”ç¨‹å‡ºå‘ç«™': 14, 'è¿”ç¨‹åˆ°è¾¾ç«™': 15}
    },
    'ä¸“å®¶è¡¨æ ¼': {
        'description': 'åºå·-ä¸“å®¶å§“å-è”ç³»ç”µè¯-èº«ä»½è¯å·-é”€å”®æ‰‹æœº-å»ç¨‹è½¦æ¬¡-è¿”ç¨‹è½¦æ¬¡-å»ç¨‹æ—¥æœŸ-è¿”ç¨‹æ—¥æœŸ-å»ç¨‹å‡ºå‘æ—¶é—´-å»ç¨‹åˆ°è¾¾æ—¶é—´-è¿”ç¨‹å‡ºå‘æ—¶é—´-è¿”ç¨‹åˆ°è¾¾æ—¶é—´-å»ç¨‹å‡ºå‘ç«™-å»ç¨‹åˆ°è¾¾ç«™-è¿”ç¨‹å‡ºå‘ç«™-è¿”ç¨‹åˆ°è¾¾ç«™ (B-Qåˆ—)',
        'mapping': {'å§“å*': 1, 'æ‰‹æœºå·ç  (å¿…å¡«)': 2, 'èº«ä»½è¯ (å‡ºæœºç¥¨å¿…é¡»å¡«å†™)': 3, 'é”€å”®æ‰‹æœº': 4, 'å»ç¨‹è½¦æ¬¡/èˆªç­': 5, 'è¿”ç¨‹è½¦æ¬¡/èˆªç­': 6, 'å»ç¨‹å‡ºå‘æ—¥æœŸ': 7, 'è¿”ç¨‹å‡ºå‘æ—¥æœŸ': 8, 'å»ç¨‹å‡ºå‘æ—¶é—´': 9, 'å»ç¨‹åˆ°è¾¾æ—¶é—´': 10, 'è¿”ç¨‹å‡ºå‘æ—¶é—´': 11, 'è¿”ç¨‹åˆ°è¾¾æ—¶é—´': 12, 'å»ç¨‹å‡ºå‘ç«™': 13, 'å»ç¨‹åˆ°è¾¾ç«™': 14, 'è¿”ç¨‹å‡ºå‘ç«™': 15, 'è¿”ç¨‹åˆ°è¾¾ç«™': 16}
    },
    'å‚ä¼šäººå‘˜': {
        'description': 'å§“å-è¯ä»¶å·-ç”µè¯-é”€å”®æ‰‹æœº-å»ç¨‹è½¦æ¬¡-è¿”ç¨‹è½¦æ¬¡-å»ç¨‹æ—¥æœŸ-è¿”ç¨‹æ—¥æœŸ-å»ç¨‹å‡ºå‘æ—¶é—´-å»ç¨‹åˆ°è¾¾æ—¶é—´-è¿”ç¨‹å‡ºå‘æ—¶é—´-è¿”ç¨‹åˆ°è¾¾æ—¶é—´-å»ç¨‹å‡ºå‘ç«™-å»ç¨‹åˆ°è¾¾ç«™-è¿”ç¨‹å‡ºå‘ç«™-è¿”ç¨‹åˆ°è¾¾ç«™ (A-Påˆ—)',
        'mapping': {'å§“å*': 0, 'èº«ä»½è¯ (å‡ºæœºç¥¨å¿…é¡»å¡«å†™)': 1, 'æ‰‹æœºå·ç  (å¿…å¡«)': 2, 'é”€å”®æ‰‹æœº': 3, 'å»ç¨‹è½¦æ¬¡/èˆªç­': 4, 'è¿”ç¨‹è½¦æ¬¡/èˆªç­': 5, 'å»ç¨‹å‡ºå‘æ—¥æœŸ': 6, 'è¿”ç¨‹å‡ºå‘æ—¥æœŸ': 7, 'å»ç¨‹å‡ºå‘æ—¶é—´': 8, 'å»ç¨‹åˆ°è¾¾æ—¶é—´': 9, 'è¿”ç¨‹å‡ºå‘æ—¶é—´': 10, 'è¿”ç¨‹åˆ°è¾¾æ—¶é—´': 11, 'å»ç¨‹å‡ºå‘ç«™': 12, 'å»ç¨‹åˆ°è¾¾ç«™': 13, 'è¿”ç¨‹å‡ºå‘ç«™': 14, 'è¿”ç¨‹åˆ°è¾¾ç«™': 15}
    }
}

# é…ç½®æ–‡ä»¶è·¯å¾„
CONFIG_FILE = 'column_mapping_config.json'

def parse_date_field(value):
    """è§£ææ—¥æœŸå­—æ®µï¼Œæ”¯æŒå¤šç§æ—¥æœŸæ ¼å¼"""
    if pd.isna(value) or value is None:
        return None
    
    # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶æ¸…ç†
    date_str = str(value).strip()
    if not date_str:
        return None
    
    # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
    date_formats = [
        '%Y-%m-%d',      # 2025-09-06
        '%Y/%m/%d',      # 2025/09/06
        '%Y.%m.%d',      # 2025.09.06
        '%m/%d/%Y',      # 09/06/2025
        '%m-%d-%Y',      # 09-06-2025
        '%d/%m/%Y',      # 06/09/2025
        '%d-%m-%Y',      # 06-09-2025
        '%Yå¹´%mæœˆ%dæ—¥',   # 2025å¹´09æœˆ06æ—¥
        '%mæœˆ%dæ—¥',       # 09æœˆ06æ—¥
        '%Y-%m-%d %H:%M:%S',  # å¸¦æ—¶é—´çš„æ ¼å¼
        '%Y/%m/%d %H:%M:%S',
    ]
    
    # å¦‚æœæ˜¯Excelçš„æ—¥æœŸåºåˆ—å·ï¼Œå°è¯•è½¬æ¢
    try:
        if isinstance(value, (int, float)) and value > 40000:  # Excelæ—¥æœŸåºåˆ—å·å¤§æ¦‚èŒƒå›´
            from datetime import datetime, timedelta
            # Excelçš„æ—¥æœŸèµ·å§‹ç‚¹æ˜¯1900-01-01ï¼Œä½†å®é™…æ˜¯1899-12-30
            excel_epoch = datetime(1899, 12, 30)
            return excel_epoch + timedelta(days=value)
    except:
        pass
    
    # å°è¯•pandasçš„æ—¥æœŸè§£æ
    try:
        parsed_date = pd.to_datetime(date_str, errors='coerce')
        if not pd.isna(parsed_date):
            return parsed_date.date()
    except:
        pass
    
    # å°è¯•å„ç§æ ¼å¼
    for fmt in date_formats:
        try:
            from datetime import datetime
            parsed = datetime.strptime(date_str, fmt)
            return parsed.date()
        except:
            continue
    
    # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›None
    return None

def parse_time_field(value):
    """è§£ææ—¶é—´å­—æ®µï¼Œæ”¯æŒå¤šç§æ—¶é—´æ ¼å¼"""
    if pd.isna(value) or value is None:
        return None
    
    # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶æ¸…ç†
    time_str = str(value).strip()
    if not time_str:
        return None
    
    # å°è¯•å¤šç§æ—¶é—´æ ¼å¼
    time_formats = [
        '%H:%M',         # 20:15
        '%H:%M:%S',      # 20:15:30
        '%I:%M %p',      # 8:15 PM
        '%I:%M:%S %p',   # 8:15:30 PM
        '%Hæ—¶%Måˆ†',       # 20æ—¶15åˆ†
        '%Hç‚¹%Måˆ†',       # 20ç‚¹15åˆ†
        '%H.%M',         # 20.15
        '%H-%M',         # 20-15
    ]
    
    # å¦‚æœæ˜¯Excelçš„æ—¶é—´åºåˆ—å·ï¼ˆå°æ•°ï¼‰ï¼Œå°è¯•è½¬æ¢
    try:
        if isinstance(value, (int, float)) and 0 <= value < 1:
            from datetime import datetime, timedelta
            # Excelæ—¶é—´æ˜¯ä¸€å¤©çš„å°æ•°éƒ¨åˆ†
            total_seconds = value * 24 * 60 * 60
            hours = int(total_seconds // 3600)
            minutes = int((total_seconds % 3600) // 60)
            from datetime import time
            return time(hours, minutes)
    except:
        pass
    
    # å°è¯•pandasçš„æ—¶é—´è§£æ
    try:
        parsed_time = pd.to_datetime(time_str, errors='coerce')
        if not pd.isna(parsed_time):
            return parsed_time.time()
    except:
        pass
    
    # å°è¯•å„ç§æ ¼å¼
    for fmt in time_formats:
        try:
            from datetime import datetime
            parsed = datetime.strptime(time_str, fmt)
            return parsed.time()
        except:
            continue
    
    # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›None
    return None

def clean_data_field(value, field_type):
    """æ¸…æ´—æ•°æ®å­—æ®µï¼Œå»é™¤ç©ºæ ¼å’Œå¤šä½™å­—ç¬¦"""
    if pd.isna(value) or value is None:
        return value
    
    # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶å»é™¤é¦–å°¾ç©ºæ ¼
    clean_value = str(value).strip()
    
    # å¦‚æœæ˜¯'nan'å­—ç¬¦ä¸²ï¼Œè¿”å›None
    if clean_value.lower() in ['nan', 'none', '', 'null']:
        return None
    
    if field_type == 'æ‰‹æœºå·ç ':
        # æ¸…æ´—æ‰‹æœºå·ï¼šå»é™¤ç©ºæ ¼ã€è¿å­—ç¬¦ã€æ‹¬å·ç­‰
        original_value = clean_value
        clean_value = re.sub(r'[\s\-\(\)\+\.]', '', clean_value)
        
        # å»é™¤å›½å®¶ä»£ç +86
        if clean_value.startswith('+86'):
            clean_value = clean_value[3:]
        elif clean_value.startswith('86') and len(clean_value) == 13:
            clean_value = clean_value[2:]
        
        # å¦‚æœæ¸…æ´—åä¸ºç©ºï¼Œè¿”å›åŸå§‹å€¼
        if not clean_value:
            return original_value
        
        # ä¸¥æ ¼æ£€æŸ¥æ‰‹æœºå·ç é•¿åº¦å’Œæ ¼å¼
        if clean_value.isdigit():
            # å¦‚æœæ˜¯12ä½ä¸”æœ«å°¾æ˜¯0ï¼Œå¯èƒ½æ˜¯Excelæ•°å­—ç²¾åº¦é—®é¢˜ï¼Œæˆªå–å‰11ä½
            if len(clean_value) == 12 and clean_value.endswith('0'):
                clean_value = clean_value[:11]
                print(f"æ‰‹æœºå·ç é•¿åº¦ä¿®æ­£: {original_value} -> {clean_value}")
            # å¦‚æœè¶…è¿‡11ä½ï¼Œæˆªå–å‰11ä½
            elif len(clean_value) > 11:
                clean_value = clean_value[:11]
                print(f"æ‰‹æœºå·ç é•¿åº¦æˆªå–: {original_value} -> {clean_value}")
        
        # ç¡®ä¿æ˜¯11ä½æ•°å­—ï¼Œå¦‚æœä¸æ˜¯ä¹Ÿè¿”å›æ¸…æ´—åçš„å€¼
        return clean_value
    
    elif field_type == 'èº«ä»½è¯':
        # æ¸…æ´—èº«ä»½è¯ï¼šå»é™¤ç©ºæ ¼ã€è¿å­—ç¬¦
        clean_value = re.sub(r'[\s\-]', '', clean_value)
        # ç¡®ä¿æ˜¯18ä½ï¼ˆåŒ…å«æœ€åä¸€ä½å¯èƒ½çš„Xï¼‰
        if len(clean_value) == 18:
            return clean_value.upper()  # Xè¦å¤§å†™
        return clean_value  # è¿”å›æ¸…æ´—åçš„å€¼ï¼Œå³ä½¿æ ¼å¼ä¸æ ‡å‡†
    
    elif field_type == 'å§“å':
        # æ¸…æ´—å§“åï¼šå»é™¤å¤šä½™ç©ºæ ¼ï¼Œä¿ç•™ä¸­é—´çš„å•ä¸ªç©ºæ ¼
        clean_value = re.sub(r'\s+', ' ', clean_value)
        return clean_value.strip()
    
    elif field_type == 'è½¦æ¬¡èˆªç­':
        # æ¸…æ´—è½¦æ¬¡/èˆªç­å·ï¼šå»é™¤ç©ºæ ¼ï¼Œç»Ÿä¸€å¤§å†™
        clean_value = re.sub(r'\s+', '', clean_value)
        return clean_value.upper()
    
    elif field_type == 'æ—¶é—´':
        # æ¸…æ´—æ—¶é—´ï¼šä¿æŒåŸå§‹æ ¼å¼ï¼Œäº¤ç»™parse_time_fieldå¤„ç†
        return clean_value
    
    else:
        # å…¶ä»–å­—æ®µï¼šåŸºæœ¬æ¸…æ´—
        return clean_value

def fuzzy_match_column(column_name, target_variants):
    """ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…ç®—æ³•åŒ¹é…åˆ—å"""
    if not column_name or not isinstance(column_name, str):
        return False
    
    # æ¸…ç†åˆ—å
    clean_col = str(column_name).strip().lower()
    
    # ç²¾ç¡®åŒ¹é…
    for variant in target_variants:
        if clean_col == variant.lower().strip():
            return True
    
    # åŒ…å«åŒ¹é…
    for variant in target_variants:
        variant_clean = variant.lower().strip()
        if variant_clean in clean_col or clean_col in variant_clean:
            if len(variant_clean) >= 2:  # é¿å…è¿‡çŸ­çš„åŒ¹é…
                return True
    
    return False

def smart_column_detection(df):
    """æ™ºèƒ½æ£€æµ‹DataFrameä¸­çš„åˆ—ååŒ¹é…"""
    detected_mapping = {}
    confidence_scores = {}
    
    for required_col in REQUIRED_COLUMNS:
        variants = COLUMN_VARIANTS.get(required_col, [])
        best_match = None
        best_score = 0
        
        for i, col in enumerate(df.columns):
            if fuzzy_match_column(col, variants):
                # è®¡ç®—åŒ¹é…ç½®ä¿¡åº¦
                score = 1.0
                
                # ç²¾ç¡®åŒ¹é…åŠ åˆ†
                if str(col).strip().lower() in [v.lower().strip() for v in variants[:3]]:
                    score += 0.5
                
                # æ•°æ®è´¨é‡åŠ åˆ†
                non_empty_ratio = df[col].notna().sum() / len(df) if len(df) > 0 else 0
                score += non_empty_ratio * 0.3
                
                if score > best_score:
                    best_score = score
                    best_match = i
        
        if best_match is not None:
            detected_mapping[required_col] = best_match
            confidence_scores[required_col] = best_score
    
    return detected_mapping, confidence_scores

def load_column_mapping():
    """åŠ è½½ç”¨æˆ·ä¿å­˜çš„åˆ—æ˜ å°„é…ç½®"""
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            pass
    return DEFAULT_COLUMN_MAPPING.copy()

def save_column_mapping(mapping):
    """ä¿å­˜ç”¨æˆ·çš„åˆ—æ˜ å°„é…ç½®"""
    try:
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(mapping, f, ensure_ascii=False, indent=2)
        return True
    except:
        return False

def apply_manual_mapping(df, column_mapping):
    """æ ¹æ®ç”¨æˆ·æŒ‡å®šçš„åˆ—æ˜ å°„åº”ç”¨åˆ°DataFrame"""
    try:
        # åˆ›å»ºæ–°çš„DataFrameï¼ŒåªåŒ…å«æ˜ å°„çš„åˆ—
        mapped_data = {}
        for required_col, col_index in column_mapping.items():
            if col_index < len(df.columns):
                # è·å–åˆ—æ•°æ®ï¼Œä¿æŒåŸå§‹æ•°æ®ç±»å‹
                col_data = df.iloc[:, col_index].copy()
                
                # åº”ç”¨æ•°æ®æ¸…æ´—ï¼Œä½†ä¿æŒåŸå§‹å€¼ç”¨äºè°ƒè¯•
                if required_col in ['æ‰‹æœºå·ç  (å¿…å¡«)', 'é”€å”®æ‰‹æœº']:
                    # å¯¹äºæ‰‹æœºå·ç ï¼Œå…ˆæ£€æŸ¥åŸå§‹æ•°æ®
                    def clean_phone_with_debug(x):
                        if pd.isna(x):
                            return x
                        original = x
                        cleaned = clean_data_field(x, 'æ‰‹æœºå·ç ')
                        # è°ƒè¯•ä¿¡æ¯ï¼šå¦‚æœæ¸…æ´—å‰åå·®å¼‚å¾ˆå¤§ï¼Œè®°å½•
                        if str(original) != str(cleaned) and len(str(original)) > 0:
                            print(f"æ‰‹æœºå·ç æ¸…æ´—: {repr(original)} -> {repr(cleaned)}")
                        return cleaned
                    col_data = col_data.apply(clean_phone_with_debug)
                elif required_col == 'èº«ä»½è¯ (å‡ºæœºç¥¨å¿…é¡»å¡«å†™)':
                    col_data = col_data.apply(lambda x: clean_data_field(x, 'èº«ä»½è¯'))
                elif required_col == 'å§“å*':
                    col_data = col_data.apply(lambda x: clean_data_field(x, 'å§“å'))
                elif required_col in ['å»ç¨‹è½¦æ¬¡/èˆªç­', 'è¿”ç¨‹è½¦æ¬¡/èˆªç­']:
                    col_data = col_data.apply(lambda x: clean_data_field(x, 'è½¦æ¬¡èˆªç­'))
                elif required_col in ['å»ç¨‹å‡ºå‘æ—¶é—´', 'å»ç¨‹åˆ°è¾¾æ—¶é—´', 'è¿”ç¨‹å‡ºå‘æ—¶é—´', 'è¿”ç¨‹åˆ°è¾¾æ—¶é—´']:
                    # å¯¹äºæ—¶é—´å­—æ®µï¼Œç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼Œä¸è¿›è¡Œå¤æ‚è§£æ
                    def process_time_field(x):
                        if pd.isna(x) or x is None:
                            return None
                        # ç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œä¿æŒåŸå§‹æ ¼å¼
                        time_str = str(x).strip()
                        if time_str.lower() in ['nan', 'none', '', 'null']:
                            return None
                        return time_str
                    col_data = col_data.apply(process_time_field)
                else:
                    # å¯¹äºå…¶ä»–å­—æ®µï¼Œè¿›è¡ŒåŸºæœ¬æ¸…æ´—
                    col_data = col_data.apply(lambda x: clean_data_field(x, 'å…¶ä»–') if not pd.isna(x) else x)
                
                mapped_data[required_col] = col_data
            else:
                mapped_data[required_col] = None
        
        new_df = pd.DataFrame(mapped_data)
        
        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œé¿å…ç±»å‹æ··åˆé—®é¢˜
        for col in new_df.columns:
            if new_df[col].dtype != 'object':
                new_df[col] = new_df[col].astype('string')
        
        return new_df
    except Exception as e:
        st.error(f"åº”ç”¨åˆ—æ˜ å°„æ—¶å‡ºé”™: {str(e)}")
        import traceback
        st.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return None

def show_manual_mapping_ui(df):
    """æ˜¾ç¤ºæ‰‹åŠ¨åˆ—æ˜ å°„ç•Œé¢"""
    st.warning("ğŸ”§ è‡ªåŠ¨è¯†åˆ«åˆ—åå¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®šåˆ—çš„å¯¹åº”å…³ç³»")
    
    # å°è¯•æ™ºèƒ½æ¨è
    detected_mapping, confidence_scores = smart_column_detection(df)
    if detected_mapping:
        st.info(f"ğŸ¤– **æ™ºèƒ½æ¨èï¼š** ç³»ç»Ÿæ£€æµ‹åˆ° {len(detected_mapping)} ä¸ªå¯èƒ½çš„åŒ¹é…åˆ—ï¼Œè¯·åœ¨ä¸‹æ–¹ç¡®è®¤æˆ–è°ƒæ•´")
        for col, idx in detected_mapping.items():
            confidence = confidence_scores.get(col, 0)
            st.write(f"  â€¢ {col} â†’ åˆ— {idx} ({df.columns[idx]}) [ç½®ä¿¡åº¦: {confidence:.2f}]")
    
    # æ·»åŠ æ“ä½œæŒ‡å¼•
    st.info("ğŸ’¡ **æ“ä½œæ­¥éª¤ï¼š** 1ï¸âƒ£ æŸ¥çœ‹ä¸‹æ–¹åˆ—ä¿¡æ¯ â†’ 2ï¸âƒ£ ä¸ºæ¯ä¸ªå­—æ®µé€‰æ‹©å¯¹åº”åˆ— â†’ 3ï¸âƒ£ é¢„è§ˆç»“æœ â†’ 4ï¸âƒ£ åº”ç”¨æ˜ å°„")
    
    # æ˜¾ç¤ºExcelæ–‡ä»¶çš„åˆ—ä¿¡æ¯
    with st.expander("ğŸ“‹ Excelæ–‡ä»¶åˆ—ä¿¡æ¯è¯¦æƒ…", expanded=True):
        st.write("**è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯é€‰æ‹©æ­£ç¡®çš„åˆ—ï¼š**")
        
        # åˆ›å»ºæ›´è¯¦ç»†çš„åˆ—ä¿¡æ¯
        col_info_data = []
        for i, col in enumerate(df.columns):
            # æ•°æ®ç»Ÿè®¡
            col_data = df.iloc[:, i]
            total_count = len(col_data)
            non_empty_count = col_data.notna().sum()
            empty_ratio = (total_count - non_empty_count) / total_count * 100 if total_count > 0 else 0
            
            # æ•°æ®ç¤ºä¾‹ï¼ˆæ›´å¤šæ ·æœ¬ï¼‰
            sample_data = col_data.dropna().head(5).tolist()
            sample_str = ', '.join([str(x)[:20] for x in sample_data])
            
            # æ•°æ®ç±»å‹åˆ†æ
            data_types = set()
            for val in sample_data[:3]:
                if pd.isna(val):
                    continue
                val_str = str(val).strip()
                if val_str.isdigit():
                    data_types.add('æ•°å­—')
                elif len(val_str) == 18 and val_str.isalnum():
                    data_types.add('èº«ä»½è¯')
                elif len(val_str) == 11 and val_str.isdigit():
                    data_types.add('æ‰‹æœºå·')
                elif any(name_word in val_str for name_word in ['å…ˆç”Ÿ', 'å¥³å£«', 'æ•™æˆ', 'åšå£«', 'åŒ»ç”Ÿ']):
                    data_types.add('å§“å')
                else:
                    data_types.add('æ–‡æœ¬')
            
            # æ™ºèƒ½æ¨èæ ‡è®°
            recommendation = ""
            if detected_mapping:
                for req_col, mapped_idx in detected_mapping.items():
                    if mapped_idx == i:
                        conf = confidence_scores.get(req_col, 0)
                        recommendation = f"ğŸ¤–æ¨è: {req_col} (ç½®ä¿¡åº¦: {conf:.2f})"
                        break
            
            col_info_data.append({
                "åˆ—ç´¢å¼•": f"åˆ— {i}",
                "åˆ—å": str(col)[:30],
                "æ•°æ®å®Œæ•´åº¦": f"{non_empty_count}/{total_count} ({100-empty_ratio:.1f}%)",
                "æ•°æ®ç±»å‹": ', '.join(data_types) if data_types else 'æœªçŸ¥',
                "æ•°æ®ç¤ºä¾‹": sample_str[:50] + "..." if len(sample_str) > 50 else sample_str,
                "æ™ºèƒ½æ¨è": recommendation
            })
        
        # ä½¿ç”¨è¡¨æ ¼æ˜¾ç¤ºåˆ—ä¿¡æ¯ - æ”¹ç”¨HTMLè¡¨æ ¼é¿å…pyarrowé—®é¢˜
        st.markdown("**åˆ—ä¿¡æ¯è¯¦è¡¨ï¼š**")
        for item in col_info_data:
            with st.container():
                cols = st.columns([1, 2, 2, 1, 3, 2])
                with cols[0]:
                    st.write(f"**{item['åˆ—ç´¢å¼•']}**")
                with cols[1]:
                    st.write(f"`{item['åˆ—å']}`")
                with cols[2]:
                    st.write(item['æ•°æ®å®Œæ•´åº¦'])
                with cols[3]:
                    st.write(item['æ•°æ®ç±»å‹'])
                with cols[4]:
                    st.write(f"_{item['æ•°æ®ç¤ºä¾‹']}_")
                with cols[5]:
                    if item['æ™ºèƒ½æ¨è']:
                        st.success(item['æ™ºèƒ½æ¨è'])
                st.divider()
        
        # æ·»åŠ æ•°æ®è´¨é‡æ€»è§ˆ
        st.write("ğŸ“Š **æ•°æ®è´¨é‡æ€»è§ˆï¼š**")
        quality_cols = st.columns(3)
        with quality_cols[0]:
            st.metric("æ€»åˆ—æ•°", len(df.columns))
        with quality_cols[1]:
            st.metric("æ€»è¡Œæ•°", len(df))
        with quality_cols[2]:
            avg_completeness = df.notna().mean().mean() * 100
            st.metric("å¹³å‡å®Œæ•´åº¦", f"{avg_completeness:.1f}%")
    
    st.markdown("### ğŸ¯ è¯·ä¸ºæ¯ä¸ªå¿…éœ€å­—æ®µé€‰æ‹©å¯¹åº”çš„åˆ—ï¼š")
    
    # åŠ è½½å·²ä¿å­˜çš„æ˜ å°„é…ç½®
    saved_mapping = load_column_mapping()
    
    # å¿«é€Ÿæ“ä½œåŒºåŸŸ
    st.markdown("### ğŸš€ å¿«é€Ÿæ“ä½œ")
    
    # æ™ºèƒ½æ¨èå¿«é€Ÿåº”ç”¨
    if detected_mapping and len(detected_mapping) >= 2:
        quick_cols = st.columns([2, 1, 1])
        with quick_cols[0]:
            st.write("**ä¸€é”®åº”ç”¨æ™ºèƒ½æ¨èï¼š**")
        with quick_cols[1]:
            if st.button("âœ¨ åº”ç”¨æ¨èæ˜ å°„", type="primary", use_container_width=True):
                mapped_df = apply_manual_mapping(df, detected_mapping)
                if mapped_df is not None:
                    if save_column_mapping(detected_mapping):
                        st.success("âœ… æ™ºèƒ½æ¨èæ˜ å°„å·²åº”ç”¨å¹¶ä¿å­˜ï¼")
                    else:
                        st.success("âœ… æ™ºèƒ½æ¨èæ˜ å°„å·²åº”ç”¨ï¼")
                    st.session_state.mapped_df = mapped_df
                    st.session_state.mapping_applied = True
                    st.rerun()
        with quick_cols[2]:
            st.write("")
    
    # é¢„è®¾é…ç½®å¿«é€Ÿé€‰æ‹©
    st.write("**æˆ–é€‰æ‹©å¸¸è§æ ¼å¼é¢„è®¾ï¼š**")
    preset_cols = st.columns([3, 1, 1])
    with preset_cols[0]:
        preset_options = ['è¯·é€‰æ‹©é¢„è®¾æ ¼å¼'] + list(PRESET_CONFIGURATIONS.keys())
        selected_preset = st.selectbox(
            "é€‰æ‹©é¢„è®¾é…ç½®",
            preset_options,
            key="preset_selector",
            help="é€‰æ‹©å¸¸è§çš„Excelæ ¼å¼é¢„è®¾ï¼Œå¿«é€Ÿé…ç½®åˆ—æ˜ å°„"
        )
        if selected_preset != 'è¯·é€‰æ‹©é¢„è®¾æ ¼å¼':
            preset_info = PRESET_CONFIGURATIONS[selected_preset]
            st.info(f"ğŸ“‹ {preset_info['description']}")
    
    with preset_cols[1]:
        if st.button("ğŸ”§ åº”ç”¨é¢„è®¾", disabled=(selected_preset == 'è¯·é€‰æ‹©é¢„è®¾æ ¼å¼'), use_container_width=True):
            if selected_preset != 'è¯·é€‰æ‹©é¢„è®¾æ ¼å¼':
                preset_mapping = PRESET_CONFIGURATIONS[selected_preset]['mapping']
                # æ£€æŸ¥é¢„è®¾æ˜ å°„æ˜¯å¦é€‚ç”¨äºå½“å‰æ•°æ®
                max_col_index = max(preset_mapping.values())
                if max_col_index < len(df.columns):
                    mapped_df = apply_manual_mapping(df, preset_mapping)
                    if mapped_df is not None:
                        if save_column_mapping(preset_mapping):
                            st.success(f"âœ… é¢„è®¾æ ¼å¼ '{selected_preset}' å·²åº”ç”¨å¹¶ä¿å­˜ï¼")
                        else:
                            st.success(f"âœ… é¢„è®¾æ ¼å¼ '{selected_preset}' å·²åº”ç”¨ï¼")
                        st.session_state.mapped_df = mapped_df
                        st.session_state.mapping_applied = True
                        st.rerun()
                    else:
                        st.error("âŒ é¢„è®¾æ ¼å¼åº”ç”¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼")
                else:
                    st.error(f"âŒ é¢„è®¾æ ¼å¼éœ€è¦è‡³å°‘ {max_col_index + 1} åˆ—ï¼Œä½†å½“å‰åªæœ‰ {len(df.columns)} åˆ—")
    
    with preset_cols[2]:
        st.write("")
    
    st.divider()
    
    st.markdown("### ğŸ¯ æ‰‹åŠ¨è°ƒæ•´æ˜ å°„ï¼ˆå¯é€‰ï¼‰")
    
    # åˆ›å»ºåˆ—é€‰æ‹©ç•Œé¢
    column_mapping = {}
    col_options = [f"åˆ— {i} ({col})" for i, col in enumerate(df.columns)]
    
    # ä½¿ç”¨åˆ—å¸ƒå±€ä½¿ç•Œé¢æ›´ç´§å‡‘
    col1, col2 = st.columns(2)
    col3, col4 = st.columns(2)
    
    with col1:
        required_col = REQUIRED_COLUMNS[0]  # å§“å
        # ä¼˜å…ˆä½¿ç”¨æ™ºèƒ½æ¨èï¼Œå…¶æ¬¡ä½¿ç”¨ä¿å­˜çš„é…ç½®
        default_index = detected_mapping.get(required_col, saved_mapping.get(required_col, 0))
        if default_index >= len(col_options):
            default_index = 0
        
        # æ·»åŠ æ¨èæ ‡è¯†
        label = f"ğŸ‘¤ {required_col}"
        if required_col in detected_mapping:
            conf = confidence_scores.get(required_col, 0)
            label += f" ğŸ¤–(æ¨è: {conf:.2f})"
            
        selected = st.selectbox(
            label,
            col_options,
            index=default_index,
            key=f"mapping_{required_col}",
            help="é€‰æ‹©åŒ…å«å§“åä¿¡æ¯çš„åˆ—"
        )
        column_mapping[required_col] = int(selected.split(' ')[1])
    
    with col2:
        required_col = REQUIRED_COLUMNS[1]  # èº«ä»½è¯
        default_index = detected_mapping.get(required_col, saved_mapping.get(required_col, 1))
        if default_index >= len(col_options):
            default_index = 1 if len(col_options) > 1 else 0
            
        label = f"ğŸ†” {required_col}"
        if required_col in detected_mapping:
            conf = confidence_scores.get(required_col, 0)
            label += f" ğŸ¤–(æ¨è: {conf:.2f})"
            
        selected = st.selectbox(
            label,
            col_options,
            index=default_index,
            key=f"mapping_{required_col}",
            help="é€‰æ‹©åŒ…å«èº«ä»½è¯å·çš„åˆ—"
        )
        column_mapping[required_col] = int(selected.split(' ')[1])
    
    with col3:
        required_col = REQUIRED_COLUMNS[2]  # æ‰‹æœºå·
        default_index = detected_mapping.get(required_col, saved_mapping.get(required_col, 2))
        if default_index >= len(col_options):
            default_index = 2 if len(col_options) > 2 else 0
            
        label = f"ğŸ“± {required_col}"
        if required_col in detected_mapping:
            conf = confidence_scores.get(required_col, 0)
            label += f" ğŸ¤–(æ¨è: {conf:.2f})"
            
        selected = st.selectbox(
            label,
            col_options,
            index=default_index,
            key=f"mapping_{required_col}",
            help="é€‰æ‹©åŒ…å«æ‰‹æœºå·ç çš„åˆ—"
        )
        column_mapping[required_col] = int(selected.split(' ')[1])
    
    with col4:
        required_col = REQUIRED_COLUMNS[3]  # é”€å”®æ‰‹æœº
        default_index = detected_mapping.get(required_col, saved_mapping.get(required_col, 3))
        if default_index >= len(col_options):
            default_index = 3 if len(col_options) > 3 else 0
            
        label = f"ğŸ“ {required_col}"
        if required_col in detected_mapping:
            conf = confidence_scores.get(required_col, 0)
            label += f" ğŸ¤–(æ¨è: {conf:.2f})"
            
        selected = st.selectbox(
            label,
            col_options,
            index=default_index,
            key=f"mapping_{required_col}",
            help="é€‰æ‹©åŒ…å«é”€å”®æ‰‹æœºå·çš„åˆ—ï¼ˆç”¨äºæ¥æ”¶å‡ºç¥¨çŸ­ä¿¡ï¼‰"
        )
        column_mapping[required_col] = int(selected.split(' ')[1])
    
    # æ“ä½œæŒ‰é’®
    col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 2])
    
    with col_btn1:
        if st.button("ğŸ” é¢„è§ˆæ˜ å°„ç»“æœ", use_container_width=True):
            preview_df = apply_manual_mapping(df, column_mapping)
            if preview_df is not None:
                st.write("ğŸ“Š **æ˜ å°„åçš„æ•°æ®é¢„è§ˆï¼š**")
                # ä½¿ç”¨å®‰å…¨çš„é¢„è§ˆæ–¹å¼
                preview_data = preview_df.head()
                for i, (idx, row) in enumerate(preview_data.iterrows()):
                    with st.expander(f"é¢„è§ˆç¬¬ {i+1} è¡Œ", expanded=(i < 2)):
                        for col in REQUIRED_COLUMNS:
                            if col in preview_df.columns:
                                value = str(row[col]) if pd.notna(row[col]) else "(ç©ºå€¼)"
                                st.write(f"**{col}:** {value}")
                
                # éªŒè¯æ•°æ®è´¨é‡
                st.write("ğŸ“ˆ **æ•°æ®è´¨é‡æ£€æŸ¥ï¼š**")
                for col in REQUIRED_COLUMNS:
                    non_empty = preview_df[col].notna().sum()
                    total = len(preview_df)
                    percentage = (non_empty / total * 100) if total > 0 else 0
                    st.write(f"  â€¢ {col}: {non_empty}/{total} è¡Œæœ‰æ•°æ® ({percentage:.1f}%)")
    
    with col_btn2:
        if st.button("âœ… åº”ç”¨æ­¤æ˜ å°„", type="primary", use_container_width=True):
            mapped_df = apply_manual_mapping(df, column_mapping)
            if mapped_df is not None:
                # ä¿å­˜æ˜ å°„é…ç½®
                if save_column_mapping(column_mapping):
                    st.success("âœ… åˆ—æ˜ å°„é…ç½®å·²ä¿å­˜ï¼Œä¸‹æ¬¡ä½¿ç”¨æ—¶ä¼šè‡ªåŠ¨åº”ç”¨ï¼")
                else:
                    st.warning("âš ï¸ æ˜ å°„é…ç½®ä¿å­˜å¤±è´¥ï¼Œä½†æœ¬æ¬¡æ˜ å°„ä»ç„¶æœ‰æ•ˆã€‚")
                
                # ä¿å­˜åˆ°session_stateè€Œä¸æ˜¯ç›´æ¥è¿”å›
                st.session_state.mapped_df = mapped_df
                st.session_state.mapping_applied = True
                st.success("ğŸ‰ æ˜ å°„åº”ç”¨æˆåŠŸï¼é¡µé¢å³å°†åˆ·æ–°...")
                st.rerun()  # é‡æ–°è¿è¡Œé¡µé¢ä»¥åº”ç”¨æ˜ å°„ç»“æœ
    
    with col_btn3:
        if st.button("ğŸ”„ é‡ç½®ä¸ºé»˜è®¤é…ç½®", use_container_width=True):
            if save_column_mapping(DEFAULT_COLUMN_MAPPING):
                st.success("âœ… å·²é‡ç½®ä¸ºé»˜è®¤é…ç½®")
                st.rerun()
    
    return None, ["ç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨æ˜ å°„"]

def smart_read_excel(uploaded_file):
    """æ™ºèƒ½è¯»å–Excelæ–‡ä»¶ï¼Œå°è¯•å¤šç§å‚æ•°ç»„åˆå’Œå¼•æ“"""
    engines = ['calamine', 'openpyxl']
    header_options = [None, 0, 1, 2, 3, 4]  # æ‰©å±•headeré€‰é¡¹
    skiprows_options = [0, 1, 2, 3]  # æ·»åŠ skiprowsé€‰é¡¹
    
    # é¦–å…ˆå°è¯•è¯»å–åŸå§‹æ•°æ®æŸ¥çœ‹ç»“æ„
    st.write("ğŸ” åˆ†æExcelæ–‡ä»¶ç»“æ„...")
    try:
        # è¯»å–å‰10è¡ŒåŸå§‹æ•°æ®
        raw_df = pd.read_excel(uploaded_file, header=None, nrows=10, engine='calamine')
        st.write("ğŸ“‹ Excelæ–‡ä»¶å‰10è¡ŒåŸå§‹æ•°æ®:")
        # ä½¿ç”¨å®‰å…¨çš„æ–¹å¼æ˜¾ç¤ºæ•°æ®ï¼Œé¿å…pyarrowé—®é¢˜
        if not raw_df.empty:
            st.write(f"æ•°æ®å½¢çŠ¶: {raw_df.shape}")
            for i in range(min(5, len(raw_df))):
                with st.expander(f"ç¬¬ {i+1} è¡Œæ•°æ®", expanded=(i < 2)):
                    for j, col_val in enumerate(raw_df.iloc[i]):
                        st.write(f"åˆ— {j}: {str(col_val)[:100]}")
        else:
            st.write("æ•°æ®ä¸ºç©º")
        
        # å°è¯•æ£€æµ‹å¯èƒ½çš„å·¥ä½œè¡¨
        try:
            xl_file = pd.ExcelFile(uploaded_file)
            if len(xl_file.sheet_names) > 1:
                st.write(f"ğŸ“Š æ£€æµ‹åˆ°å¤šä¸ªå·¥ä½œè¡¨: {xl_file.sheet_names}")
        except:
            pass
            
    except Exception as e:
        st.write(f"âš ï¸ æ— æ³•è¯»å–åŸå§‹æ•°æ®: {str(e)}")
    
    best_result = None
    best_score = 0
    
    for engine in engines:
        st.write(f"ğŸ” å°è¯•ä½¿ç”¨ {engine} å¼•æ“...")
        
        for skiprows in skiprows_options:
            for header_val in header_options:
                try:
                    st.write(f"  ğŸ“‹ å°è¯• skiprows={skiprows}, header={header_val}...")
                    
                    # å°è¯•è¯»å–æ•°æ®
                    if skiprows > 0:
                        df = pd.read_excel(uploaded_file, header=header_val, skiprows=skiprows, engine=engine)
                    else:
                        df = pd.read_excel(uploaded_file, header=header_val, engine=engine)
                    
                    # è·³è¿‡ç©ºçš„DataFrame
                    if df.empty:
                        st.write(f"    âš ï¸ è¯»å–ç»“æœä¸ºç©º")
                        continue
                    
                    # æ¸…ç†åˆ—å
                    original_columns = list(df.columns)
                    if df.columns.dtype == 'object':
                        df.columns = df.columns.astype(str).str.strip()
                    
                    # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                    st.write(f"    ğŸ“Š æ•°æ®å½¢çŠ¶: {df.shape}")
                    st.write(f"    ğŸ“‹ åŸå§‹åˆ—å: {original_columns[:5]}...")
                    st.write(f"    ğŸ§¹ æ¸…ç†ååˆ—å: {list(df.columns)[:5]}...")
                    
                    # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
                    if not df.empty:
                        st.write("    ğŸ“„ å‰3è¡Œæ•°æ®:")
                        # ä½¿ç”¨å®‰å…¨çš„æ–¹å¼æ˜¾ç¤ºæ•°æ®ï¼Œé¿å…pyarrowé—®é¢˜
                        preview_df = df.head(3)
                        for i in range(len(preview_df)):
                            with st.expander(f"    ç¬¬ {i+1} è¡Œ", expanded=(i == 0)):
                                for col in preview_df.columns:
                                    value = str(preview_df.iloc[i][col]) if pd.notna(preview_df.iloc[i][col]) else "(ç©ºå€¼)"
                                    st.write(f"      {col}: {value[:50]}...")
                    
                    # ä½¿ç”¨æ™ºèƒ½æ¨¡ç³ŠåŒ¹é…è®¡ç®—åˆ†æ•°
                    detected_mapping, confidence_scores = smart_column_detection(df)
                    
                    # è®¡ç®—æ€»ä½“åŒ¹é…åˆ†æ•°
                    score = len(detected_mapping)
                    avg_confidence = sum(confidence_scores.values()) / len(confidence_scores) if confidence_scores else 0
                    total_score = score + avg_confidence
                    
                    found_cols = list(detected_mapping.keys())
                    
                    # é¢å¤–åŠ åˆ†ï¼šåˆ—åä¸æ˜¯Unnamed
                    unnamed_count = sum(1 for col in df.columns if 'Unnamed' in str(col))
                    if unnamed_count < len(df.columns) * 0.5:  # å¦‚æœUnnamedåˆ—å°‘äºä¸€åŠ
                        total_score += 0.5
                    
                    st.write(f"    ğŸ¯ æ™ºèƒ½åŒ¹é…åˆ†æ•°: {total_score:.2f} (æ‰¾åˆ° {score}/{len(REQUIRED_COLUMNS)} åˆ—)")
                    st.write(f"    ğŸ“‹ åŒ¹é…è¯¦æƒ…: {found_cols}")
                    if confidence_scores:
                        st.write(f"    ğŸ“Š ç½®ä¿¡åº¦: {', '.join([f'{k}: {v:.2f}' for k, v in confidence_scores.items()])}")
                    
                    if total_score > best_score:
                        best_score = total_score
                        # å¦‚æœæ‰¾åˆ°äº†æ™ºèƒ½åŒ¹é…ï¼Œåº”ç”¨æ˜ å°„
                        if detected_mapping:
                            mapped_df = apply_manual_mapping(df, detected_mapping)
                            if mapped_df is not None:
                                best_result = (mapped_df.copy(), engine, skiprows, header_val, [], detected_mapping)
                            else:
                                best_result = (df.copy(), engine, skiprows, header_val, found_cols, detected_mapping)
                        else:
                            best_result = (df.copy(), engine, skiprows, header_val, found_cols, {})
                        st.write(f"    â­ å½“å‰æœ€ä½³ç»“æœï¼")
                    
                    # å¦‚æœæ‰¾åˆ°æ‰€æœ‰å¿…éœ€åˆ—ï¼Œç›´æ¥è¿”å›
                    if score == len(REQUIRED_COLUMNS):
                        if detected_mapping:
                            mapped_df = apply_manual_mapping(df, detected_mapping)
                            if mapped_df is not None:
                                st.success(f"ğŸ‰ æ™ºèƒ½åŒ¹é…æˆåŠŸï¼æ‰¾åˆ°æ‰€æœ‰å¿…éœ€åˆ—ï¼Œç½®ä¿¡åº¦: {avg_confidence:.2f}")
                                st.info(f"ğŸ“‹ ä½¿ç”¨å‚æ•°: engine={engine}, skiprows={skiprows}, header={header_val}")
                                return mapped_df, None
                        st.success(f"ğŸ‰ æ‰¾åˆ°æ‰€æœ‰å¿…éœ€åˆ—ï¼ä½¿ç”¨ engine={engine}, skiprows={skiprows}, header={header_val}")
                        return df, None
                        
                except Exception as e:
                    st.write(f"    âŒ å¤±è´¥: {str(e)[:100]}...")
                    continue
    
    # è¿”å›æœ€ä½³ç»“æœ
    if best_result:
        if len(best_result) == 6:  # æ–°æ ¼å¼ï¼šåŒ…å«detected_mapping
            df, engine, skiprows, header_val, found_cols, detected_mapping = best_result
            missing_cols = [col for col in REQUIRED_COLUMNS if col not in found_cols]
            
            if detected_mapping and not missing_cols:
                st.success(f"ğŸ‰ æ™ºèƒ½åŒ¹é…æˆåŠŸï¼è‡ªåŠ¨è¯†åˆ«æ‰€æœ‰å¿…éœ€åˆ—")
                st.info(f"ğŸ“ˆ ä½¿ç”¨å‚æ•°: engine={engine}, skiprows={skiprows}, header={header_val}")
                st.info(f"ğŸ”— æ™ºèƒ½æ˜ å°„: {', '.join([f'{k}â†’åˆ—{v}' for k, v in detected_mapping.items()])}")
                return df, None
            elif detected_mapping:
                st.info(f"ğŸ“ˆ æ™ºèƒ½åŒ¹é…éƒ¨åˆ†æˆåŠŸ: engine={engine}, skiprows={skiprows}, header={header_val}")
                st.info(f"âœ… æ‰¾åˆ°åˆ—: {found_cols}")
                st.info(f"ğŸ”— æ™ºèƒ½æ˜ å°„: {', '.join([f'{k}â†’åˆ—{v}' for k, v in detected_mapping.items()])}")
                if missing_cols:
                    st.warning(f"âš ï¸ ä»ç¼ºå°‘åˆ—: {missing_cols}")
                return df, missing_cols
        else:  # æ—§æ ¼å¼å…¼å®¹
            df, engine, skiprows, header_val, found_cols = best_result
            missing_cols = [col for col in REQUIRED_COLUMNS if col not in found_cols]
            
        st.info(f"ğŸ“ˆ ä½¿ç”¨æœ€ä½³åŒ¹é…ç»“æœ: engine={engine}, skiprows={skiprows}, header={header_val}")
        st.info(f"âœ… æ‰¾åˆ°åˆ—: {found_cols}")
        if missing_cols:
            st.warning(f"âš ï¸ ä»ç¼ºå°‘åˆ—: {missing_cols}")
        return df, missing_cols
    
    # å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ä¿å­˜çš„æ˜ å°„é…ç½®
    st.write("ğŸ”§ å°è¯•ä½¿ç”¨ä¿å­˜çš„åˆ—æ˜ å°„é…ç½®...")
    try:
        # è¯»å–åŸå§‹æ•°æ®ï¼ˆä¸æŒ‡å®šheaderï¼‰
        df_raw = pd.read_excel(uploaded_file, header=None, engine='calamine')
        if not df_raw.empty:
            # å°è¯•ä½¿ç”¨ä¿å­˜çš„æ˜ å°„é…ç½®
            saved_mapping = load_column_mapping()
            if saved_mapping:
                st.write(f"ğŸ“‹ æ‰¾åˆ°ä¿å­˜çš„æ˜ å°„é…ç½®: {saved_mapping}")
                mapped_df = apply_manual_mapping(df_raw, saved_mapping)
                if mapped_df is not None and not mapped_df.empty:
                    # æ£€æŸ¥æ˜ å°„åçš„æ•°æ®æ˜¯å¦æœ‰æ•ˆ
                    valid_data = True
                    for col in REQUIRED_COLUMNS:
                        if col not in mapped_df.columns or mapped_df[col].isna().all():
                            valid_data = False
                            break
                    
                    if valid_data:
                        st.success("ğŸ‰ ä½¿ç”¨ä¿å­˜çš„åˆ—æ˜ å°„é…ç½®æˆåŠŸï¼")
                        return mapped_df, None
                    else:
                        st.write("âš ï¸ ä¿å­˜çš„æ˜ å°„é…ç½®æ— æ•ˆï¼Œéœ€è¦é‡æ–°é…ç½®")
            
            # å¦‚æœä¿å­˜çš„é…ç½®æ— æ•ˆæˆ–ä¸å­˜åœ¨ï¼Œæ˜¾ç¤ºæ‰‹åŠ¨æ˜ å°„ç•Œé¢
            st.write("ğŸ”§ æ˜¾ç¤ºæ‰‹åŠ¨åˆ—æ˜ å°„ç•Œé¢...")
            return show_manual_mapping_ui(df_raw)
            
    except Exception as e:
        st.write(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}")
    
    return None, ["æ— æ³•è¯»å–æ–‡ä»¶æˆ–è¯†åˆ«æ­£ç¡®çš„åˆ—å"]

# --- Part 1: ä¸Šä¼ æ–‡ä»¶ä¸é€‰æ‹©ä¸“å®¶ ---
st.header("ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ å®¢æˆ·ä¿¡æ¯è¡¨å¹¶é€‰æ‹©ä¸“å®¶")

uploaded_file = st.file_uploader("è¯·ä¸Šä¼ åŒ…å«ä¸“å®¶ä¿¡æ¯çš„Excelæ–‡ä»¶ (.xlsx)", type=['xlsx'])

if 'expert_data' not in st.session_state:
    st.session_state.expert_data = None

if uploaded_file is not None:
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ˜ å°„ç»“æœåœ¨session_stateä¸­
    if hasattr(st.session_state, 'mapping_applied') and st.session_state.mapping_applied and hasattr(st.session_state, 'mapped_df'):
        # ä½¿ç”¨å·²æ˜ å°„çš„æ•°æ®
        df = st.session_state.mapped_df
        missing_cols = None
        st.success("âœ… ä½¿ç”¨å·²é…ç½®çš„åˆ—æ˜ å°„")
        
        # æ˜¾ç¤ºå½“å‰æ•°æ®æ¦‚è§ˆ
        with st.expander("ğŸ“Š å½“å‰æ•°æ®æ¦‚è§ˆ", expanded=False):
            st.write(f"**æ•°æ®è¡Œæ•°ï¼š** {len(df)} è¡Œ")
            st.write("**åˆ—ä¿¡æ¯ï¼š**")
            for col in REQUIRED_COLUMNS:
                if col in df.columns:
                    non_empty = df[col].notna().sum()
                    st.write(f"  â€¢ {col}: {non_empty}/{len(df)} è¡Œæœ‰æ•°æ®")
                    
                    # ç‰¹åˆ«æ˜¾ç¤ºæ‰‹æœºå·ç å­—æ®µçš„è¯¦ç»†ä¿¡æ¯
                    if col in ['æ‰‹æœºå·ç  (å¿…å¡«)', 'é”€å”®æ‰‹æœº']:
                        phone_data = df[col].dropna()
                        if len(phone_data) > 0:
                            st.write(f"    ğŸ“± {col} æ ·æœ¬æ•°æ®:")
                            for i, phone in enumerate(phone_data.head(3)):
                                st.write(f"      - ç¬¬{i+1}ä¸ª: {repr(phone)} (ç±»å‹: {type(phone).__name__})")
            
            # ä½¿ç”¨å®‰å…¨çš„æ•°æ®æ˜¾ç¤ºæ–¹å¼
            st.write("**æ•°æ®é¢„è§ˆï¼ˆå‰5è¡Œï¼‰ï¼š**")
            preview_data = df.head()
            for i, (idx, row) in enumerate(preview_data.iterrows()):
                with st.expander(f"ç¬¬ {i+1} è¡Œæ•°æ®", expanded=(i < 2)):
                    for col in REQUIRED_COLUMNS:
                        if col in df.columns:
                            value = str(row[col]) if pd.notna(row[col]) else "(ç©ºå€¼)"
                            # å¯¹æ‰‹æœºå·ç å­—æ®µæ˜¾ç¤ºæ›´è¯¦ç»†ä¿¡æ¯
                            if col in ['æ‰‹æœºå·ç  (å¿…å¡«)', 'é”€å”®æ‰‹æœº'] and pd.notna(row[col]):
                                original = row[col]
                                cleaned = clean_data_field(original, 'æ‰‹æœºå·ç ')
                                st.write(f"**{col}:** {value}")
                                st.write(f"  - åŸå§‹å€¼: {repr(original)}")
                                st.write(f"  - æ¸…æ´—å: {repr(cleaned)}")
                            else:
                                st.write(f"**{col}:** {value}")
            
            # æä¾›é‡æ–°æ˜ å°„é€‰é¡¹
            if st.button("ğŸ”„ é‡æ–°è¿›è¡Œåˆ—æ˜ å°„"):
                if hasattr(st.session_state, 'mapped_df'):
                    del st.session_state.mapped_df
                if hasattr(st.session_state, 'mapping_applied'):
                    del st.session_state.mapping_applied
                st.rerun()
    else:
        # é‡ç½®æ˜ å°„çŠ¶æ€
        st.session_state.mapping_applied = False
        
        # æ˜¾ç¤ºæ–‡ä»¶å¤„ç†çŠ¶æ€
        with st.spinner("ğŸ”„ æ­£åœ¨åˆ†æExcelæ–‡ä»¶..."):
            with st.expander("ğŸ“Š Excelæ–‡ä»¶è¯»å–è°ƒè¯•ä¿¡æ¯", expanded=False):
                df, missing_cols = smart_read_excel(uploaded_file)
        
    if df is not None:
        if missing_cols and missing_cols != ["ç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨æ˜ å°„"]:
            st.error(f"âš ï¸ è‡ªåŠ¨è¯†åˆ«éƒ¨åˆ†å¤±è´¥ï¼ç¼ºå°‘ä»¥ä¸‹å¿…éœ€åˆ—: {', '.join(missing_cols)}")
            
            with st.expander("ğŸ” è¯¦ç»†è¯Šæ–­ä¿¡æ¯", expanded=True):
                st.write("ğŸ“‹ **æ£€æµ‹åˆ°çš„æ‰€æœ‰åˆ—å:**")
                col_analysis = []
                for i, col in enumerate(df.columns):
                    # åˆ†ææ¯åˆ—å¯èƒ½çš„ç”¨é€”
                    analysis = "æœªçŸ¥"
                    col_str = str(col).lower().strip()
                    if any(name_word in col_str for name_word in ['å§“å', 'åå­—', 'name', 'ä¸“å®¶']):
                        analysis = "ğŸ¤” å¯èƒ½æ˜¯å§“ååˆ—"
                    elif any(id_word in col_str for id_word in ['èº«ä»½è¯', 'id', 'è¯ä»¶']):
                        analysis = "ğŸ¤” å¯èƒ½æ˜¯èº«ä»½è¯åˆ—"
                    elif any(phone_word in col_str for phone_word in ['æ‰‹æœº', 'ç”µè¯', 'phone', 'è”ç³»']):
                        analysis = "ğŸ¤” å¯èƒ½æ˜¯æ‰‹æœºå·åˆ—"
                    
                    col_analysis.append({
                        "åˆ—ç´¢å¼•": f"åˆ— {i}",
                        "åˆ—å": str(col),
                        "åˆ†æ": analysis
                    })
                
                # ç›´æ¥æ˜¾ç¤ºåˆ—åˆ†æç»“æœï¼Œé¿å…DataFrameè½¬æ¢é—®é¢˜
                st.markdown("**åˆ—åˆ†æç»“æœï¼š**")
                for item in col_analysis:
                    st.write(f"â€¢ {item['åˆ—ç´¢å¼•']}: '{item['åˆ—å']}' - {item['åˆ†æ']}")
                
                # ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹å¼æ˜¾ç¤ºè¡¨æ ¼ï¼Œé¿å…pyarrowé—®é¢˜
                if len(col_analysis) > 0:
                    st.markdown("**è¯¦ç»†åˆ†æè¡¨æ ¼ï¼š**")
                    for i, item in enumerate(col_analysis):
                        with st.container():
                            cols = st.columns([1, 3, 6])
                            with cols[0]:
                                st.write(f"**{item['åˆ—ç´¢å¼•']}**")
                            with cols[1]:
                                st.write(f"`{item['åˆ—å']}`")
                            with cols[2]:
                                st.write(item['åˆ†æ'])
                            if i < len(col_analysis) - 1:
                                st.divider()
                
                st.markdown("""
                ### ğŸ› ï¸ è§£å†³æ–¹æ¡ˆ
                1. **æ™ºèƒ½æ¨è** - ç³»ç»Ÿå·²å°è¯•æ™ºèƒ½åŒ¹é…ï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹æ¨èç»“æœ
                2. **é¢„è®¾æ ¼å¼** - å°è¯•ä½¿ç”¨å¸¸è§æ ¼å¼é¢„è®¾å¿«é€Ÿé…ç½®
                3. **æ‰‹åŠ¨æ˜ å°„** - åœ¨ä¸‹æ–¹æ‰‹åŠ¨é€‰æ‹©æ­£ç¡®çš„åˆ—å¯¹åº”å…³ç³»
                4. **æ–‡ä»¶æ£€æŸ¥** - ç¡®è®¤Excelæ–‡ä»¶åŒ…å«å®Œæ•´çš„å§“åã€èº«ä»½è¯ã€æ‰‹æœºå·ä¿¡æ¯
                """)
            
            # ä¸è¦åœæ­¢ï¼Œè®©ç”¨æˆ·ç»§ç»­ä½¿ç”¨æ‰‹åŠ¨æ˜ å°„
            st.info("ğŸ’¡ **åˆ«æ‹…å¿ƒï¼** è¯·ä½¿ç”¨ä¸‹æ–¹çš„æ‰‹åŠ¨æ˜ å°„åŠŸèƒ½æ¥å®Œæˆé…ç½®ã€‚")
        elif missing_cols == ["ç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨æ˜ å°„"]:
            # æ˜¾ç¤ºæ‰‹åŠ¨æ˜ å°„ç•Œé¢ï¼Œç­‰å¾…ç”¨æˆ·æ“ä½œ
            st.info("ğŸ“ è¯·åœ¨ä¸Šæ–¹å®Œæˆåˆ—æ˜ å°„é…ç½®åï¼Œé¡µé¢å°†è‡ªåŠ¨åˆ·æ–°ã€‚")
            st.stop()
        else:
            # æˆåŠŸè¯»å–ï¼Œç»§ç»­å¤„ç†
            df.dropna(subset=['å§“å*'], inplace=True)
            expert_list = ["---è¯·é€‰æ‹©---"] + df['å§“å*'].tolist()
            selected_expert_name = st.selectbox("è¯·ä»è¡¨æ ¼ä¸­é€‰æ‹©ä¸€ä½ä¸“å®¶ï¼š", expert_list)

            if selected_expert_name and selected_expert_name != "---è¯·é€‰æ‹©---":
                selected_row = df[df['å§“å*'] == selected_expert_name].iloc[0]
                st.session_state.expert_data = selected_row
                
                # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºé€‰ä¸­çš„ä¸“å®¶æ•°æ®
                with st.expander("ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šé€‰ä¸­çš„ä¸“å®¶åŸå§‹æ•°æ®", expanded=False):
                    st.write("**DataFrameåˆ—åï¼š**")
                    st.write(list(df.columns))
                    st.write("\n**é€‰ä¸­ä¸“å®¶çš„åŸå§‹æ•°æ®ï¼š**")
                    for col in df.columns:
                        value = selected_row[col]
                        st.write(f"- {col}: {repr(value)} (ç±»å‹: {type(value).__name__})")
                    
                    # æ£€æŸ¥æ‰‹æœºå·ç å­—æ®µæ˜¯å¦å­˜åœ¨ä¸”æœ‰å€¼
                    phone_col = 'æ‰‹æœºå·ç  (å¿…å¡«)'
                    if phone_col in df.columns:
                        phone_value = selected_row[phone_col]
                        st.write(f"\n**æ‰‹æœºå·ç å­—æ®µè¯¦ç»†ä¿¡æ¯ï¼š**")
                        st.write(f"- åŸå§‹å€¼: {repr(phone_value)}")
                        st.write(f"- æ˜¯å¦ä¸ºç©º: {pd.isna(phone_value)}")
                        st.write(f"- è½¬æ¢ä¸ºå­—ç¬¦ä¸²: {repr(str(phone_value))}")
                        if not pd.isna(phone_value):
                            cleaned = clean_data_field(phone_value, 'æ‰‹æœºå·ç ')
                            st.write(f"- æ¸…æ´—å: {repr(cleaned)}")
                    else:
                        st.error(f"âŒ æœªæ‰¾åˆ°æ‰‹æœºå·ç å­—æ®µ '{phone_col}'")
                        st.write(f"å¯ç”¨å­—æ®µ: {list(df.columns)}")
    else:
        st.error("âŒ æ— æ³•è¯»å–Excelæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€‚")
        st.session_state.expert_data = None
else:
    # æ¸…é™¤æ˜ å°„çŠ¶æ€å½“æ²¡æœ‰æ–‡ä»¶ä¸Šä¼ æ—¶
    if hasattr(st.session_state, 'mapping_applied'):
        st.session_state.mapping_applied = False
    if hasattr(st.session_state, 'mapped_df'):
        del st.session_state.mapped_df
    st.session_state.expert_data = None
    
    # æ˜¾ç¤ºè¯¦ç»†ä½¿ç”¨è¯´æ˜
    st.info("ğŸ“ **ä½¿ç”¨è¯´æ˜ï¼š** è¯·ä¸Šä¼ åŒ…å«ä¸“å®¶ä¿¡æ¯çš„Excelæ–‡ä»¶ï¼Œç³»ç»Ÿå°†æ™ºèƒ½è¯†åˆ«å§“åã€èº«ä»½è¯å’Œæ‰‹æœºå·ç åˆ—ã€‚")
    
    with st.expander("ğŸ“– è¯¦ç»†è¯´æ˜å’Œå¸¸è§é—®é¢˜", expanded=False):
        st.markdown("""
        ### ğŸ“‹ æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
        - âœ… Excelæ–‡ä»¶ (.xlsx)
        - âœ… æ”¯æŒå¤šç§è¡¨å¤´è¡Œä½ç½®
        - âœ… æ”¯æŒä¸­è‹±æ–‡åˆ—å
        
        ### ğŸ¯ å¿…éœ€çš„åˆ—ä¿¡æ¯
        ç³»ç»Ÿéœ€è¦è¯†åˆ«ä»¥ä¸‹å››ç±»ä¿¡æ¯ï¼š
        1. **å§“åä¿¡æ¯** - æ”¯æŒï¼šå§“åã€åå­—ã€ä¸“å®¶å§“åã€å‚ä¼šäººå§“åç­‰
        2. **èº«ä»½è¯ä¿¡æ¯** - æ”¯æŒï¼šèº«ä»½è¯ã€èº«ä»½è¯å·ã€è¯ä»¶å·ã€IDç­‰
        3. **æ‰‹æœºå·ä¿¡æ¯** - æ”¯æŒï¼šæ‰‹æœºã€æ‰‹æœºå·ã€ç”µè¯ã€è”ç³»ç”µè¯ç­‰
        4. **é”€å”®æ‰‹æœºä¿¡æ¯** - æ”¯æŒï¼šé”€å”®æ‰‹æœºã€ç¥¨åŠ¡æ‰‹æœºã€å‡ºç¥¨æ‰‹æœºã€ç¬¬äºŒæ‰‹æœºç­‰
        
        ### ğŸš€ æ™ºèƒ½è¯†åˆ«åŠŸèƒ½
        - ğŸ¤– **æ™ºèƒ½æ¨¡ç³ŠåŒ¹é…** - è‡ªåŠ¨è¯†åˆ«å¸¸è§åˆ—åå˜ä½“
        - ğŸ“Š **æ•°æ®è´¨é‡åˆ†æ** - è¯„ä¼°æ•°æ®å®Œæ•´åº¦å’Œç±»å‹
        - ğŸ”§ **é¢„è®¾æ ¼å¼æ”¯æŒ** - å¿«é€Ÿåº”ç”¨å¸¸è§Excelæ ¼å¼
        - ğŸ’¾ **é…ç½®è®°å¿†** - ä¿å­˜æ˜ å°„é…ç½®ä¾›ä¸‹æ¬¡ä½¿ç”¨
        
        ### â“ å¸¸è§é—®é¢˜è§£å†³
        - **è‡ªåŠ¨è¯†åˆ«å¤±è´¥ï¼Ÿ** â†’ ç³»ç»Ÿæä¾›æ™ºèƒ½æ¨èå’Œæ‰‹åŠ¨æ˜ å°„
        - **åˆ—åä¸æ ‡å‡†ï¼Ÿ** â†’ æ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼Œå¦‚"å§“å"åŒ¹é…"ä¸“å®¶å§“å"
        - **è¡¨å¤´ä½ç½®ä¸å¯¹ï¼Ÿ** â†’ è‡ªåŠ¨å°è¯•å¤šç§è¡¨å¤´è¡Œä½ç½®
        - **æ•°æ®æ ¼å¼å¤æ‚ï¼Ÿ** â†’ æä¾›é¢„è®¾æ ¼å¼å¿«é€Ÿé…ç½®
        
        ### ğŸ’¡ ä½¿ç”¨æŠ€å·§
        1. ç¡®ä¿Excelæ–‡ä»¶ä¸­åŒ…å«å®Œæ•´çš„å§“åã€èº«ä»½è¯ã€æ‰‹æœºå·ä¿¡æ¯
        2. å¦‚æœæœ‰å¤šä¸ªå·¥ä½œè¡¨ï¼Œè¯·ä½¿ç”¨ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨
        3. å»ºè®®å°†é‡è¦ä¿¡æ¯æ”¾åœ¨å‰å‡ åˆ—ä»¥æé«˜è¯†åˆ«å‡†ç¡®ç‡
        """)
    
    # æ·»åŠ æ–‡ä»¶è¦æ±‚æç¤º
    st.markdown("""
    <div style="background-color: #e8f4fd; padding: 15px; border-radius: 10px; border-left: 4px solid #1f77b4; color: #1a1a1a;">
    <h4 style="margin-top: 0; color: #1f77b4;">ğŸ“ æ–‡ä»¶ä¸Šä¼ è¦æ±‚</h4>
    <ul style="color: #333333;">
        <li><strong>æ–‡ä»¶æ ¼å¼ï¼š</strong> ä»…æ”¯æŒ .xlsx æ ¼å¼</li>
        <li><strong>æ•°æ®è¦æ±‚ï¼š</strong> åŒ…å«å§“åã€èº«ä»½è¯ã€æ‰‹æœºå·ã€é”€å”®æ‰‹æœºå››åˆ—ä¿¡æ¯</li>
        <li><strong>é”€å”®æ‰‹æœºï¼š</strong> ç”¨äºæ¥æ”¶æœ€ç»ˆå‡ºç¥¨çŸ­ä¿¡çš„æ‰‹æœºå·ç </li>
        <li><strong>æ•°æ®è´¨é‡ï¼š</strong> å»ºè®®æ•°æ®å®Œæ•´åº¦ > 80%</li>
        <li><strong>æ–‡ä»¶å¤§å°ï¼š</strong> å»ºè®® < 10MBï¼Œæ”¯æŒæœ€å¤š1000è¡Œæ•°æ®</li>
    </ul>
    </div>
    """, unsafe_allow_html=True)


st.markdown("\n---\n")

# --- Part 2: ç”Ÿæˆè¯¢ä»·ä¿¡æ¯ (è‡ªåŠ¨å¡«å……) ---
st.header("ç¬¬äºŒæ­¥ï¼šç”Ÿæˆå‘é€ç»™ç¥¨åŠ¡çš„ã€è¯¢ä»·ä¿¡æ¯ã€‘")

# ä½¿ç”¨å…¨å®½å¸ƒå±€

# ä»session stateè·å–æ•°æ®æ—¶ï¼Œä½¿ç”¨æ­£ç¡®çš„åˆ—åï¼ˆåŒ…å«ç©ºæ ¼ï¼‰
def safe_get_value(data, key, default=''):
    """å®‰å…¨è·å–æ•°æ®å€¼ï¼Œé¿å…æ˜¾ç¤ºnanæˆ–None"""
    if data is None:
        return default
    value = data.get(key, default)
    if pd.isna(value) or value is None:
        return default
    str_value = str(value).strip()
    if str_value.lower() in ['nan', 'none', 'null', '']:
        return default
    # å¦‚æœdefaultæ˜¯Noneï¼Œç›´æ¥è¿”å›åŸå§‹å€¼ç”¨äºè¿›ä¸€æ­¥å¤„ç†
    if default is None:
        return value
    return str_value

def validate_phone_number(phone_str):
    """éªŒè¯æ‰‹æœºå·ç æ ¼å¼æ˜¯å¦ä¸º11ä½æ•°å­—"""
    if not phone_str or not isinstance(phone_str, str):
        return False
    
    # æ¸…ç†æ‰‹æœºå·ç ï¼šå»é™¤ç©ºæ ¼ã€è¿å­—ç¬¦ã€æ‹¬å·ç­‰
    clean_phone = re.sub(r'[\s\-\(\)\+\.]', '', phone_str.strip())
    
    # å»é™¤å›½å®¶ä»£ç +86
    if clean_phone.startswith('+86'):
        clean_phone = clean_phone[3:]
    elif clean_phone.startswith('86') and len(clean_phone) == 13:
        clean_phone = clean_phone[2:]
    
    # æ£€æŸ¥æ˜¯å¦ä¸º11ä½æ•°å­—
    return len(clean_phone) == 11 and clean_phone.isdigit()

expert_name_val = safe_get_value(st.session_state.expert_data, 'å§“å*')
expert_id_val = safe_get_value(st.session_state.expert_data, 'èº«ä»½è¯ (å‡ºæœºç¥¨å¿…é¡»å¡«å†™)')
expert_phone_val = safe_get_value(st.session_state.expert_data, 'æ‰‹æœºå·ç  (å¿…å¡«)')
sales_phone_val = safe_get_value(st.session_state.expert_data, 'é”€å”®æ‰‹æœº')

# è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºå®é™…æå–çš„æ•°æ®
if st.session_state.expert_data is not None:
    with st.expander("ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šå®é™…æå–çš„æ•°æ®", expanded=False):
        st.write("**åŸå§‹ä¸“å®¶æ•°æ®ï¼š**")
        for key, value in st.session_state.expert_data.items():
            st.write(f"- {key}: {repr(value)}")
outbound_flight_val = safe_get_value(st.session_state.expert_data, 'å»ç¨‹è½¦æ¬¡/èˆªç­')
return_flight_val = safe_get_value(st.session_state.expert_data, 'è¿”ç¨‹è½¦æ¬¡/èˆªç­')

# è·å–ç«™ç‚¹ä¿¡æ¯
outbound_from_val = safe_get_value(st.session_state.expert_data, 'å»ç¨‹å‡ºå‘ç«™')
outbound_to_val = safe_get_value(st.session_state.expert_data, 'å»ç¨‹åˆ°è¾¾ç«™')
return_from_val = safe_get_value(st.session_state.expert_data, 'è¿”ç¨‹å‡ºå‘ç«™')
return_to_val = safe_get_value(st.session_state.expert_data, 'è¿”ç¨‹åˆ°è¾¾ç«™')

# è·å–å¹¶è§£ææ—¥æœŸæ•°æ®
outbound_date_val = None
return_date_val = None
if st.session_state.expert_data is not None:
    # è§£æå»ç¨‹å‡ºå‘æ—¥æœŸ
    outbound_date_raw = safe_get_value(st.session_state.expert_data, 'å»ç¨‹å‡ºå‘æ—¥æœŸ')
    if outbound_date_raw:
        outbound_date_val = parse_date_field(outbound_date_raw)
    
    # è§£æè¿”ç¨‹å‡ºå‘æ—¥æœŸ
    return_date_raw = safe_get_value(st.session_state.expert_data, 'è¿”ç¨‹å‡ºå‘æ—¥æœŸ')
    if return_date_raw:
        return_date_val = parse_date_field(return_date_raw)

# è·å–æ—¶é—´æ•°æ®ï¼ˆå­—ç¬¦ä¸²æ ¼å¼ï¼‰
outbound_time_val = safe_get_value(st.session_state.expert_data, 'å»ç¨‹å‡ºå‘æ—¶é—´')
outbound_arrival_time_val = safe_get_value(st.session_state.expert_data, 'å»ç¨‹åˆ°è¾¾æ—¶é—´')
return_time_val = safe_get_value(st.session_state.expert_data, 'è¿”ç¨‹å‡ºå‘æ—¶é—´')
return_arrival_time_val = safe_get_value(st.session_state.expert_data, 'è¿”ç¨‹åˆ°è¾¾æ—¶é—´')

# è°ƒè¯•ä¿¡æ¯æ˜¾ç¤ºï¼ˆä»…åœ¨æœ‰æ•°æ®æ—¶æ˜¾ç¤ºï¼‰
if st.session_state.expert_data is not None:
    with st.expander("ğŸ” æ•°æ®æå–è°ƒè¯•ä¿¡æ¯", expanded=False):
        st.write("\n**å¤„ç†åçš„å€¼ï¼š**")
        st.write(f"- å§“å: {repr(expert_name_val)}")
        st.write(f"- èº«ä»½è¯: {repr(expert_id_val)}")
        st.write(f"- æ‰‹æœºå·ç : {repr(expert_phone_val)}")
        st.write(f"- é”€å”®æ‰‹æœº: {repr(sales_phone_val)}")
        st.write("\n**æ—¶é—´å­—æ®µæå–ç»“æœï¼š**")
        st.write(f"- å»ç¨‹å‡ºå‘æ—¶é—´: {repr(outbound_time_val)}")
        st.write(f"- å»ç¨‹åˆ°è¾¾æ—¶é—´: {repr(outbound_arrival_time_val)}")
        st.write(f"- è¿”ç¨‹å‡ºå‘æ—¶é—´: {repr(return_time_val)}")
        st.write(f"- è¿”ç¨‹åˆ°è¾¾æ—¶é—´: {repr(return_arrival_time_val)}")

# ä¸“å®¶åŸºæœ¬ä¿¡æ¯
st.subheader("ä¸“å®¶åŸºæœ¬ä¿¡æ¯ï¼ˆè‡ªåŠ¨å¡«å……ï¼‰ï¼š")
col_info1, col_info2 = st.columns(2)
with col_info1:
    expert_name = st.text_input("ä¸“å®¶å§“å*", value=expert_name_val)
    expert_id = st.text_input("èº«ä»½è¯å·*", value=expert_id_val)
with col_info2:
    # ä¸“å®¶æ‰‹æœºå·ç è¾“å…¥æ¡†ï¼ˆå¸¦éªŒè¯ï¼‰
    expert_phone = st.text_input("æ‰‹æœºå·ç *", value=expert_phone_val, key="expert_phone_input")
    
    # éªŒè¯ä¸“å®¶æ‰‹æœºå·ç æ ¼å¼
    if expert_phone and not validate_phone_number(expert_phone):
        st.error("âŒ æ‰‹æœºå·ç æ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·è¾“å…¥11ä½æ•°å­—")
    
    # é”€å”®æ‰‹æœºå·ç è¾“å…¥æ¡†ï¼ˆå¸¦éªŒè¯ï¼‰
    sales_phone = st.text_input("é”€å”®æ‰‹æœºï¼ˆæ¥æ”¶å‡ºç¥¨çŸ­ä¿¡ï¼‰", value=sales_phone_val, help="ç”¨äºæ¥æ”¶æœ€ç»ˆå‡ºç¥¨çŸ­ä¿¡çš„æ‰‹æœºå·ç ", key="sales_phone_input")
    
    # éªŒè¯é”€å”®æ‰‹æœºå·ç æ ¼å¼ï¼ˆä»…åœ¨æœ‰è¾“å…¥æ—¶éªŒè¯ï¼‰
    if sales_phone and sales_phone.strip() and not validate_phone_number(sales_phone):
        st.error("âŒ é”€å”®æ‰‹æœºå·ç æ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·è¾“å…¥11ä½æ•°å­—")

st.markdown("---")

# äº¤é€šä¿¡æ¯è¾“å…¥
st.subheader("äº¤é€šä¿¡æ¯è¯¦ç»†å¡«å†™ï¼š")

# å»ç¨‹ä¿¡æ¯
st.markdown("### ğŸ›« å»ç¨‹ä¿¡æ¯")
col_out1, col_out2, col_out3, col_out4 = st.columns(4)
with col_out1:
    outbound_transport = st.selectbox("äº¤é€šæ–¹å¼", ["é£æœº", "é«˜é“", "ç«è½¦", "æ±½è½¦"], key="outbound_transport")
    outbound_date = st.date_input("å‡ºå‘æ—¥æœŸ", value=outbound_date_val, key="outbound_date", help="å·²ä»è¡¨æ ¼è‡ªåŠ¨å¡«å……ï¼Œå¯æ‰‹åŠ¨ä¿®æ”¹" if outbound_date_val else None)
with col_out2:
    outbound_flight = st.text_input("è½¦æ¬¡/èˆªç­å·", value=outbound_flight_val, placeholder="å¦‚ï¼šCA1234", key="outbound_flight", help="å·²ä»è¡¨æ ¼è‡ªåŠ¨å¡«å……ï¼Œå¯æ‰‹åŠ¨ä¿®æ”¹")
    outbound_time = st.text_input("å‡ºå‘æ—¶é—´", value=outbound_time_val, key="outbound_time", placeholder="å¦‚ï¼š20:15", help="å·²ä»è¡¨æ ¼è‡ªåŠ¨å¡«å……ï¼Œå¯æ‰‹åŠ¨ä¿®æ”¹" if outbound_time_val else None)
with col_out3:
    outbound_from = st.text_input("å‡ºå‘ç«™/æœºåœº", value=outbound_from_val, placeholder="å¦‚ï¼šåŒ—äº¬é¦–éƒ½æœºåœº", key="outbound_from", help="å·²ä»è¡¨æ ¼è‡ªåŠ¨å¡«å……ï¼Œå¯æ‰‹åŠ¨ä¿®æ”¹" if outbound_from_val else None)
    outbound_to = st.text_input("åˆ°è¾¾ç«™/æœºåœº", value=outbound_to_val, placeholder="å¦‚ï¼šä¸Šæµ·è™¹æ¡¥æœºåœº", key="outbound_to", help="å·²ä»è¡¨æ ¼è‡ªåŠ¨å¡«å……ï¼Œå¯æ‰‹åŠ¨ä¿®æ”¹" if outbound_to_val else None)
with col_out4:
    outbound_arrival_time = st.text_input("åˆ°è¾¾æ—¶é—´", value=outbound_arrival_time_val, key="outbound_arrival_time", placeholder="å¦‚ï¼š22:40", help="å·²ä»è¡¨æ ¼è‡ªåŠ¨å¡«å……ï¼Œå¯æ‰‹åŠ¨ä¿®æ”¹" if outbound_arrival_time_val else None)

# è¿”ç¨‹ä¿¡æ¯
st.markdown("### ğŸ›¬ è¿”ç¨‹ä¿¡æ¯")
col_ret1, col_ret2, col_ret3, col_ret4 = st.columns(4)
with col_ret1:
    return_transport = st.selectbox("äº¤é€šæ–¹å¼", ["é£æœº", "é«˜é“", "ç«è½¦", "æ±½è½¦"], key="return_transport")
    return_date = st.date_input("å‡ºå‘æ—¥æœŸ", value=return_date_val, key="return_date", help="å·²ä»è¡¨æ ¼è‡ªåŠ¨å¡«å……ï¼Œå¯æ‰‹åŠ¨ä¿®æ”¹" if return_date_val else None)
with col_ret2:
    return_flight = st.text_input("è½¦æ¬¡/èˆªç­å·", value=return_flight_val, placeholder="å¦‚ï¼šCA5678", key="return_flight", help="å·²ä»è¡¨æ ¼è‡ªåŠ¨å¡«å……ï¼Œå¯æ‰‹åŠ¨ä¿®æ”¹")
    return_time = st.text_input("å‡ºå‘æ—¶é—´", value=return_time_val, key="return_time", placeholder="å¦‚ï¼š15:45", help="å·²ä»è¡¨æ ¼è‡ªåŠ¨å¡«å……ï¼Œå¯æ‰‹åŠ¨ä¿®æ”¹" if return_time_val else None)
with col_ret3:
    return_from = st.text_input("å‡ºå‘ç«™/æœºåœº", value=return_from_val, placeholder="å¦‚ï¼šä¸Šæµ·è™¹æ¡¥æœºåœº", key="return_from", help="å·²ä»è¡¨æ ¼è‡ªåŠ¨å¡«å……ï¼Œå¯æ‰‹åŠ¨ä¿®æ”¹" if return_from_val else None)
    return_to = st.text_input("åˆ°è¾¾ç«™/æœºåœº", value=return_to_val, placeholder="å¦‚ï¼šåŒ—äº¬é¦–éƒ½æœºåœº", key="return_to", help="å·²ä»è¡¨æ ¼è‡ªåŠ¨å¡«å……ï¼Œå¯æ‰‹åŠ¨ä¿®æ”¹" if return_to_val else None)
with col_ret4:
    return_arrival_time = st.text_input("åˆ°è¾¾æ—¶é—´", value=return_arrival_time_val, key="return_arrival_time", placeholder="å¦‚ï¼š18:10", help="å·²ä»è¡¨æ ¼è‡ªåŠ¨å¡«å……ï¼Œå¯æ‰‹åŠ¨ä¿®æ”¹" if return_arrival_time_val else None)

st.markdown("---")

# ç”Ÿæˆè¯¢ä»·ä¿¡æ¯
st.subheader("ç”Ÿæˆçš„è¯¢ä»·ä¿¡æ¯ï¼š")
if st.button("âœ… ç‚¹å‡»ç”Ÿæˆè¯¢ä»·ä¿¡æ¯", type="primary"):
    if not expert_name or not expert_id or not expert_phone:
        st.warning("ä¸“å®¶å§“åã€èº«ä»½è¯å·å’Œæ‰‹æœºå·ä¸ºå¿…å¡«é¡¹ã€‚è¯·å…ˆä¸Šä¼ è¡¨æ ¼å¹¶é€‰æ‹©ä¸“å®¶ã€‚")
    else:
        # æ ¼å¼åŒ–æ—¥æœŸä¸ºxxæœˆxxæ—¥
        def format_date(date_obj):
            if date_obj:
                return f"{date_obj.month}æœˆ{date_obj.day}æ—¥"
            return ""
        
        # æ ¼å¼åŒ–æ—¶é—´å­—ç¬¦ä¸²ä¸ºHH:MMæ ¼å¼
        def format_time(time_str):
            if time_str and time_str.strip():
                time_clean = time_str.strip()
                # å¦‚æœæ—¶é—´åŒ…å«ç§’æ•°ï¼ˆå¦‚HH:MM:SSï¼‰ï¼Œåªå–å‰5ä½ï¼ˆHH:MMï¼‰
                if ':' in time_clean:
                    parts = time_clean.split(':')
                    if len(parts) >= 2:
                        # ç¡®ä¿å°æ—¶å’Œåˆ†é’Ÿéƒ½æ˜¯ä¸¤ä½æ•°
                        hour = parts[0].zfill(2)
                        minute = parts[1].zfill(2)
                        return f"{hour}:{minute}"
                return time_clean
            return ""
        
        # æŒ‰ç…§æ–°æ ¼å¼ç”Ÿæˆè¯¢ä»·ä¿¡æ¯
        inquiry_text = f"{expert_name} {expert_id}\n"
        
        # æ‰‹æœºå·ç è¡Œ
        phone_line = expert_phone
        if sales_phone and sales_phone.strip():
            phone_line += f"/{sales_phone}"
        inquiry_text += phone_line + "\n"
        
        # å»ç¨‹ä¿¡æ¯
        if outbound_transport and outbound_date:
            outbound_line = f"{outbound_transport} {format_date(outbound_date)}"
            if outbound_flight:
                outbound_line += f" {outbound_flight}"
            if outbound_time:
                outbound_line += f" {format_time(outbound_time)}"
            if outbound_from:
                outbound_line += f" {outbound_from}"
            if outbound_to:
                outbound_line += f" {outbound_to}"
            if outbound_arrival_time:
                outbound_line += f" {format_time(outbound_arrival_time)}"
            inquiry_text += outbound_line + "\n"
        
        # è¿”ç¨‹ä¿¡æ¯
        if return_transport and return_date:
            return_line = f"{return_transport} {format_date(return_date)}"
            if return_flight:
                return_line += f" {return_flight}"
            if return_time:
                return_line += f" {format_time(return_time)}"
            if return_from:
                return_line += f" {return_from}"
            if return_to:
                return_line += f" {return_to}"
            if return_arrival_time:
                return_line += f" {format_time(return_arrival_time)}"
            inquiry_text += return_line
        
        st.code(inquiry_text, language="text")
        
        # æç¤ºä¿¡æ¯
        if sales_phone and sales_phone.strip():
            st.success("âœ… è¯¢ä»·ä¿¡æ¯å·²ç”Ÿæˆï¼è¯·ç‚¹å‡»å³ä¸Šè§’çš„å¤åˆ¶æŒ‰é’®ï¼Œç„¶åå°†ä¿¡æ¯å‘é€ç»™ç¥¨åŠ¡ã€‚")
            st.info("ğŸ’¡ é”€å”®æ‰‹æœºå·å°†ç”¨äºæ¥æ”¶æœ€ç»ˆå‡ºç¥¨çŸ­ä¿¡ã€‚")
        else:
            st.success("âœ… è¯¢ä»·ä¿¡æ¯å·²ç”Ÿæˆï¼è¯·ç‚¹å‡»å³ä¸Šè§’çš„å¤åˆ¶æŒ‰é’®ï¼Œç„¶åå°†ä¿¡æ¯å‘é€ç»™ç¥¨åŠ¡ã€‚")
            st.warning("âš ï¸ å»ºè®®å¡«å†™é”€å”®æ‰‹æœºå·ï¼Œç”¨äºæ¥æ”¶å‡ºç¥¨çŸ­ä¿¡ã€‚")

st.markdown("\n---\n")

# --- Part 3: å¤„ç†ç¥¨åŠ¡å›å¤ (åŠŸèƒ½ä¸å˜) ---
st.header("ç¬¬ä¸‰æ­¥ï¼šå¤„ç†ç¥¨åŠ¡å›å¤ï¼Œç”Ÿæˆã€ä¸“å®¶ç¡®è®¤ä¿¡æ¯ã€‘")

col3, col4 = st.columns(2)

with col3:
    st.subheader("è¯·ç²˜è´´ç¥¨åŠ¡çš„å®Œæ•´å›å¤ï¼š")
    agent_reply = st.text_area("ï¼ˆè¯·å°†å¾®ä¿¡ä¸­ç¥¨åŠ¡çš„å›å¤åŸæ–‡ï¼ŒåŒ…å«ä»·æ ¼ï¼Œå®Œæ•´ç²˜è´´åˆ°æ­¤å¤„ï¼‰", height=250, key="agent_reply")

with col4:
    st.subheader("å¤„ç†åå¯å‘ç»™ä¸“å®¶çš„ä¿¡æ¯ï¼š")
    if st.button("ğŸª„ æ¸…æ´—ä»·æ ¼å¹¶ç”Ÿæˆç¡®è®¤ä¿¡æ¯"):
        if agent_reply:
            # æ›´ç²¾ç¡®çš„ä»·æ ¼æ¸…æ´—ï¼šåªåŒ¹é…æ˜ç¡®çš„ä»·æ ¼æ ¼å¼ï¼Œé¿å…è¯¯åˆ èˆªç­æ—¶é—´ç­‰é‡è¦ä¿¡æ¯
            # åŒ¹é…æ¨¡å¼ï¼š
            # 1. æ•°å­—+å…ƒï¼ˆå¦‚ï¼š1110å…ƒã€1120 å…ƒï¼‰
            # 2. ä»·æ ¼+å†’å·+æ•°å­—ï¼ˆå¦‚ï¼šä»·æ ¼ï¼š1110ã€ä»·æ ¼ 1110ï¼‰
            # 3. å•ç‹¬ä¸€è¡Œçš„çº¯æ•°å­—ä»·æ ¼ï¼ˆå¦‚ï¼šå•ç‹¬ä¸€è¡Œçš„1110ï¼‰
            # 4. è´¹ç”¨ç›¸å…³è¡¨è¿°ï¼ˆå¦‚ï¼šè´¹ç”¨1110ã€æ€»è®¡1110ç­‰ï¼‰
            price_patterns = [
                r'\d+\s*å…ƒ',  # æ•°å­—+å…ƒ
                r'ä»·æ ¼\s*[:ï¼š]?\s*\d+',  # ä»·æ ¼+æ•°å­—
                r'è´¹ç”¨\s*[:ï¼š]?\s*\d+',  # è´¹ç”¨+æ•°å­—
                r'æ€»è®¡\s*[:ï¼š]?\s*\d+',  # æ€»è®¡+æ•°å­—
                r'åˆè®¡\s*[:ï¼š]?\s*\d+',  # åˆè®¡+æ•°å­—
                r'^\s*\d{4}\s*$',  # å•ç‹¬ä¸€è¡Œçš„4ä½æ•°å­—ï¼ˆä»·æ ¼ï¼‰
                r'\b\d+\s*RMB\b',  # æ•°å­—+RMB
                r'\b\d+\s*rmb\b',  # æ•°å­—+rmb
            ]
            
            cleaned_text = agent_reply
            for pattern in price_patterns:
                cleaned_text = re.sub(pattern, '', cleaned_text, flags=re.MULTILINE)
            # ä¿ç•™èˆªç­å·æ ¼å¼ï¼ˆå¦‚CA1234ã€MU5678ç­‰ï¼‰ï¼Œåªåˆ é™¤å¯èƒ½çš„6ä½çº¯æ•°å­—ä»·æ ¼ä»£ç 
            cleaned_text = re.sub(r'(?<!\w)[0-9]{6}(?!\w)', '', cleaned_text)
            lines = cleaned_text.split('\n')
            non_empty_lines = [line.strip() for line in lines if line.strip()]
            final_text = '\n'.join(non_empty_lines)
            expert_confirmation_text = f"ã€è¯·ç¡®è®¤ä»¥ä¸‹èˆªç­ä¿¡æ¯ã€‘\n{final_text}"
            st.code(expert_confirmation_text, language="text")
            st.success("ä»·æ ¼å·²ç§»é™¤ï¼è¯·ç‚¹å‡»å³ä¸Šè§’å¤åˆ¶æŒ‰é’®ï¼Œå°†æ­¤ä¿¡æ¯å‘é€ç»™ä¸“å®¶ç¡®è®¤ã€‚")
        else:
            st.warning("è¯·å…ˆåœ¨å·¦ä¾§ç²˜è´´ç¥¨åŠ¡çš„å›å¤ã€‚")